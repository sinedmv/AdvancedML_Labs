- Реализовать линейную или сверточную нейронную сеть из двух скрытых слоев.
- Обучить ее на датасете MNIST.
- Сравнить качество обучения при использовании различных функций активации
(ReLU, GELU, Swish, Softplus обязательно, остальные – по желанию). Функции
активации реализовывать!
- Построить график для функций активации точности от эпох..