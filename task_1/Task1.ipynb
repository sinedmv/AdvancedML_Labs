{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T11:48:34.101145Z",
     "start_time": "2025-02-15T11:48:06.354938Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Загрузка данных MNIST с использованием TensorFlow\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Нормализация данных\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# Выбор первых 500 элементов\n",
    "X_train = X_train[:500]\n",
    "y_train = y_train[:500]\n",
    "X_test = X_test[:100]\n",
    "y_test = y_test[:100]\n",
    "\n",
    "# Преобразование данных в двумерный массив\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# One-hot encoding of labels\n",
    "def one_hot_encode(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "y_train_encoded = one_hot_encode(y_train, 10)\n",
    "y_test_encoded = one_hot_encode(y_test, 10)\n",
    "\n",
    "class ActivationFunction:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def activate(self, z):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def derivative(self, z):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "    def activate(self, z):\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def derivative(self, z):\n",
    "        return np.where(z > 0, 1, 0)\n",
    "\n",
    "class GELU(ActivationFunction):\n",
    "    def activate(self, z):\n",
    "        return 0.5 * z * (1 + np.tanh(np.sqrt(2/np.pi) * (z + 0.044715 * z**3)))\n",
    "\n",
    "    def derivative(self, z):\n",
    "        tanh = np.tanh(np.sqrt(2/np.pi) * (z + 0.044715 * z**3))\n",
    "        derivative = 0.5 * (1 + tanh) + 0.5 * z * (np.sqrt(2/np.pi) * (1 + 0.13403 * z**2) * (1 - tanh**2))\n",
    "        return derivative\n",
    "\n",
    "class Softmax(ActivationFunction):\n",
    "    def activate(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    def derivative(self, z):\n",
    "        # Softmax derivative is usually handled differently in practice\n",
    "        pass\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, layer_config):\n",
    "        self.layers = []\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        # Initialize layers\n",
    "        prev_size = input_size\n",
    "        for config in layer_config:\n",
    "            activation = config['activation']()\n",
    "            self.layers.append({\n",
    "                'size': config['size'],\n",
    "                'activation': activation,\n",
    "                'z': None,\n",
    "                'a': None\n",
    "            })\n",
    "            current_size = config['size']\n",
    "            self.weights.append(np.random.randn(prev_size, current_size) * 0.01)\n",
    "            self.biases.append(np.zeros((1, current_size)))\n",
    "            prev_size = current_size\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        a = X\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            z = np.dot(a, self.weights[i]) + self.biases[i]\n",
    "            a = layer['activation'].activate(z)\n",
    "            layer['z'] = z\n",
    "            layer['a'] = a\n",
    "        return a\n",
    "\n",
    "    def backward_propagation(self, X, y, learning_rate):\n",
    "        m = X.shape[0]\n",
    "        dz = (self.layers[-1]['a'] - y) / m\n",
    "\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            dW = np.dot(self.layers[i-1]['a'].T, dz) if i != 0 else np.dot(X.T, dz)\n",
    "            db = np.sum(dz, axis=0, keepdims=True)\n",
    "            if i != 0:\n",
    "                dz = np.dot(dz, self.weights[i].T) * self.layers[i-1]['activation'].derivative(self.layers[i-1]['z'])\n",
    "            self.weights[i] -= learning_rate * dW\n",
    "            self.biases[i] -= learning_rate * db\n",
    "\n",
    "    def train(self, X, y, learning_rate, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward_propagation(X)\n",
    "            self.backward_propagation(X, y, learning_rate)\n",
    "            loss = self.cross_entropy_loss(y, output)\n",
    "            print(f'Epoch {epoch}, Loss: {loss}')\n",
    "            print(f'Accuracy {self.accuracy(y_test, self.predict(X_test))}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward_propagation(X)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        return np.mean(y_true == y_pred)\n",
    "\n",
    "    def cross_entropy_loss(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        return -np.sum(np.log(y_pred + 1e-15) * y_true) / m\n",
    "\n",
    "# Example usage with 3 hidden layers\n",
    "input_size = X_train.shape[1]\n",
    "layer_config = [\n",
    "    {'size': 128, 'activation': ReLU},\n",
    "    {'size': 64, 'activation': GELU},\n",
    "    {'size': 10, 'activation': Softmax}  # Output layer with Softmax\n",
    "]\n",
    "\n",
    "nn = NeuralNetwork(input_size, layer_config)\n",
    "nn.train(X_train, y_train_encoded, learning_rate=0.05, epochs=1000)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3025565478578285\n",
      "Accuracy 0.14\n",
      "Epoch 1, Loss: 2.302442941523964\n",
      "Accuracy 0.14\n",
      "Epoch 2, Loss: 2.302330454476418\n",
      "Accuracy 0.14\n",
      "Epoch 3, Loss: 2.3022190751429226\n",
      "Accuracy 0.14\n",
      "Epoch 4, Loss: 2.3021087935754787\n",
      "Accuracy 0.14\n",
      "Epoch 5, Loss: 2.3019995984946084\n",
      "Accuracy 0.14\n",
      "Epoch 6, Loss: 2.301891479771177\n",
      "Accuracy 0.14\n",
      "Epoch 7, Loss: 2.3017844263597476\n",
      "Accuracy 0.14\n",
      "Epoch 8, Loss: 2.3016784281088105\n",
      "Accuracy 0.14\n",
      "Epoch 9, Loss: 2.3015734748220122\n",
      "Accuracy 0.14\n",
      "Epoch 10, Loss: 2.3014695560280325\n",
      "Accuracy 0.14\n",
      "Epoch 11, Loss: 2.3013666617519903\n",
      "Accuracy 0.14\n",
      "Epoch 12, Loss: 2.301264781913623\n",
      "Accuracy 0.14\n",
      "Epoch 13, Loss: 2.30116390637104\n",
      "Accuracy 0.14\n",
      "Epoch 14, Loss: 2.3010640247741514\n",
      "Accuracy 0.14\n",
      "Epoch 15, Loss: 2.3009651277778524\n",
      "Accuracy 0.14\n",
      "Epoch 16, Loss: 2.300867206048314\n",
      "Accuracy 0.14\n",
      "Epoch 17, Loss: 2.3007702503136205\n",
      "Accuracy 0.14\n",
      "Epoch 18, Loss: 2.300674250784455\n",
      "Accuracy 0.14\n",
      "Epoch 19, Loss: 2.30057919799479\n",
      "Accuracy 0.14\n",
      "Epoch 20, Loss: 2.3004850828211083\n",
      "Accuracy 0.14\n",
      "Epoch 21, Loss: 2.300391894448087\n",
      "Accuracy 0.14\n",
      "Epoch 22, Loss: 2.3002996249106626\n",
      "Accuracy 0.14\n",
      "Epoch 23, Loss: 2.300208264966209\n",
      "Accuracy 0.14\n",
      "Epoch 24, Loss: 2.300117805823713\n",
      "Accuracy 0.14\n",
      "Epoch 25, Loss: 2.3000282382971102\n",
      "Accuracy 0.14\n",
      "Epoch 26, Loss: 2.2999395537265706\n",
      "Accuracy 0.14\n",
      "Epoch 27, Loss: 2.2998517425484724\n",
      "Accuracy 0.14\n",
      "Epoch 28, Loss: 2.2997647971600315\n",
      "Accuracy 0.14\n",
      "Epoch 29, Loss: 2.299678708519088\n",
      "Accuracy 0.14\n",
      "Epoch 30, Loss: 2.299593468888807\n",
      "Accuracy 0.14\n",
      "Epoch 31, Loss: 2.299509069513522\n",
      "Accuracy 0.14\n",
      "Epoch 32, Loss: 2.2994255021792713\n",
      "Accuracy 0.14\n",
      "Epoch 33, Loss: 2.299342758758615\n",
      "Accuracy 0.14\n",
      "Epoch 34, Loss: 2.2992608305620528\n",
      "Accuracy 0.14\n",
      "Epoch 35, Loss: 2.2991797097067255\n",
      "Accuracy 0.14\n",
      "Epoch 36, Loss: 2.2990993883686435\n",
      "Accuracy 0.14\n",
      "Epoch 37, Loss: 2.299019858649695\n",
      "Accuracy 0.14\n",
      "Epoch 38, Loss: 2.298941113024198\n",
      "Accuracy 0.14\n",
      "Epoch 39, Loss: 2.298863143388773\n",
      "Accuracy 0.14\n",
      "Epoch 40, Loss: 2.2987859415508685\n",
      "Accuracy 0.14\n",
      "Epoch 41, Loss: 2.2987094998557405\n",
      "Accuracy 0.14\n",
      "Epoch 42, Loss: 2.2986338109806113\n",
      "Accuracy 0.14\n",
      "Epoch 43, Loss: 2.2985588676723947\n",
      "Accuracy 0.14\n",
      "Epoch 44, Loss: 2.298484662855505\n",
      "Accuracy 0.14\n",
      "Epoch 45, Loss: 2.2984111891784553\n",
      "Accuracy 0.14\n",
      "Epoch 46, Loss: 2.2983384396981474\n",
      "Accuracy 0.14\n",
      "Epoch 47, Loss: 2.298266406243506\n",
      "Accuracy 0.14\n",
      "Epoch 48, Loss: 2.2981950811004714\n",
      "Accuracy 0.14\n",
      "Epoch 49, Loss: 2.2981244578922033\n",
      "Accuracy 0.14\n",
      "Epoch 50, Loss: 2.2980545295272057\n",
      "Accuracy 0.14\n",
      "Epoch 51, Loss: 2.2979852893679795\n",
      "Accuracy 0.14\n",
      "Epoch 52, Loss: 2.2979167303661208\n",
      "Accuracy 0.14\n",
      "Epoch 53, Loss: 2.29784884605455\n",
      "Accuracy 0.14\n",
      "Epoch 54, Loss: 2.2977816294056836\n",
      "Accuracy 0.14\n",
      "Epoch 55, Loss: 2.297715073217325\n",
      "Accuracy 0.14\n",
      "Epoch 56, Loss: 2.2976491714077447\n",
      "Accuracy 0.14\n",
      "Epoch 57, Loss: 2.2975839172591175\n",
      "Accuracy 0.14\n",
      "Epoch 58, Loss: 2.2975193039600073\n",
      "Accuracy 0.14\n",
      "Epoch 59, Loss: 2.2974553257597443\n",
      "Accuracy 0.14\n",
      "Epoch 60, Loss: 2.297391975870949\n",
      "Accuracy 0.14\n",
      "Epoch 61, Loss: 2.2973292481475514\n",
      "Accuracy 0.14\n",
      "Epoch 62, Loss: 2.297267136074772\n",
      "Accuracy 0.14\n",
      "Epoch 63, Loss: 2.2972056339857927\n",
      "Accuracy 0.14\n",
      "Epoch 64, Loss: 2.2971447357108343\n",
      "Accuracy 0.14\n",
      "Epoch 65, Loss: 2.2970844344510315\n",
      "Accuracy 0.14\n",
      "Epoch 66, Loss: 2.297024724267524\n",
      "Accuracy 0.14\n",
      "Epoch 67, Loss: 2.296965599284369\n",
      "Accuracy 0.14\n",
      "Epoch 68, Loss: 2.29690705329231\n",
      "Accuracy 0.14\n",
      "Epoch 69, Loss: 2.2968490812009534\n",
      "Accuracy 0.14\n",
      "Epoch 70, Loss: 2.2967916768236254\n",
      "Accuracy 0.14\n",
      "Epoch 71, Loss: 2.2967348349167587\n",
      "Accuracy 0.14\n",
      "Epoch 72, Loss: 2.296678549519981\n",
      "Accuracy 0.14\n",
      "Epoch 73, Loss: 2.2966228139721627\n",
      "Accuracy 0.14\n",
      "Epoch 74, Loss: 2.2965676232265344\n",
      "Accuracy 0.14\n",
      "Epoch 75, Loss: 2.296512971965365\n",
      "Accuracy 0.14\n",
      "Epoch 76, Loss: 2.2964588551434035\n",
      "Accuracy 0.14\n",
      "Epoch 77, Loss: 2.296405267397128\n",
      "Accuracy 0.14\n",
      "Epoch 78, Loss: 2.2963522029828884\n",
      "Accuracy 0.14\n",
      "Epoch 79, Loss: 2.296299656702907\n",
      "Accuracy 0.14\n",
      "Epoch 80, Loss: 2.2962476238949194\n",
      "Accuracy 0.14\n",
      "Epoch 81, Loss: 2.2961960985231475\n",
      "Accuracy 0.14\n",
      "Epoch 82, Loss: 2.2961450759128694\n",
      "Accuracy 0.14\n",
      "Epoch 83, Loss: 2.296094550587832\n",
      "Accuracy 0.14\n",
      "Epoch 84, Loss: 2.29604451799079\n",
      "Accuracy 0.14\n",
      "Epoch 85, Loss: 2.2959949725925726\n",
      "Accuracy 0.14\n",
      "Epoch 86, Loss: 2.295945909645554\n",
      "Accuracy 0.14\n",
      "Epoch 87, Loss: 2.2958973239475653\n",
      "Accuracy 0.14\n",
      "Epoch 88, Loss: 2.2958492110107818\n",
      "Accuracy 0.14\n",
      "Epoch 89, Loss: 2.295801566474721\n",
      "Accuracy 0.14\n",
      "Epoch 90, Loss: 2.29575438566018\n",
      "Accuracy 0.14\n",
      "Epoch 91, Loss: 2.295707663751955\n",
      "Accuracy 0.14\n",
      "Epoch 92, Loss: 2.295661395078506\n",
      "Accuracy 0.14\n",
      "Epoch 93, Loss: 2.2956155747567073\n",
      "Accuracy 0.14\n",
      "Epoch 94, Loss: 2.2955701990641573\n",
      "Accuracy 0.14\n",
      "Epoch 95, Loss: 2.295525263823631\n",
      "Accuracy 0.14\n",
      "Epoch 96, Loss: 2.2954807641228454\n",
      "Accuracy 0.14\n",
      "Epoch 97, Loss: 2.2954366953334175\n",
      "Accuracy 0.14\n",
      "Epoch 98, Loss: 2.295393052693088\n",
      "Accuracy 0.14\n",
      "Epoch 99, Loss: 2.295349832194207\n",
      "Accuracy 0.14\n",
      "Epoch 100, Loss: 2.2953070294623488\n",
      "Accuracy 0.14\n",
      "Epoch 101, Loss: 2.295264640489236\n",
      "Accuracy 0.14\n",
      "Epoch 102, Loss: 2.295222660844697\n",
      "Accuracy 0.14\n",
      "Epoch 103, Loss: 2.295181086349922\n",
      "Accuracy 0.14\n",
      "Epoch 104, Loss: 2.2951399127123198\n",
      "Accuracy 0.14\n",
      "Epoch 105, Loss: 2.2950991354897043\n",
      "Accuracy 0.14\n",
      "Epoch 106, Loss: 2.295058750226971\n",
      "Accuracy 0.14\n",
      "Epoch 107, Loss: 2.2950187535568465\n",
      "Accuracy 0.14\n",
      "Epoch 108, Loss: 2.294979140952884\n",
      "Accuracy 0.14\n",
      "Epoch 109, Loss: 2.2949399085296047\n",
      "Accuracy 0.14\n",
      "Epoch 110, Loss: 2.2949010521219892\n",
      "Accuracy 0.14\n",
      "Epoch 111, Loss: 2.2948625686953297\n",
      "Accuracy 0.14\n",
      "Epoch 112, Loss: 2.2948244536861484\n",
      "Accuracy 0.14\n",
      "Epoch 113, Loss: 2.2947867038760497\n",
      "Accuracy 0.14\n",
      "Epoch 114, Loss: 2.294749315326182\n",
      "Accuracy 0.14\n",
      "Epoch 115, Loss: 2.2947122840774954\n",
      "Accuracy 0.14\n",
      "Epoch 116, Loss: 2.294675606490798\n",
      "Accuracy 0.14\n",
      "Epoch 117, Loss: 2.2946392784845253\n",
      "Accuracy 0.14\n",
      "Epoch 118, Loss: 2.294603296720082\n",
      "Accuracy 0.14\n",
      "Epoch 119, Loss: 2.294567658026859\n",
      "Accuracy 0.14\n",
      "Epoch 120, Loss: 2.2945323587762863\n",
      "Accuracy 0.14\n",
      "Epoch 121, Loss: 2.294497395583043\n",
      "Accuracy 0.14\n",
      "Epoch 122, Loss: 2.2944627642136193\n",
      "Accuracy 0.14\n",
      "Epoch 123, Loss: 2.294428461757453\n",
      "Accuracy 0.14\n",
      "Epoch 124, Loss: 2.2943944857478766\n",
      "Accuracy 0.14\n",
      "Epoch 125, Loss: 2.2943608320811144\n",
      "Accuracy 0.14\n",
      "Epoch 126, Loss: 2.2943274972913943\n",
      "Accuracy 0.14\n",
      "Epoch 127, Loss: 2.29429447742774\n",
      "Accuracy 0.14\n",
      "Epoch 128, Loss: 2.294261769441049\n",
      "Accuracy 0.14\n",
      "Epoch 129, Loss: 2.29422937056573\n",
      "Accuracy 0.14\n",
      "Epoch 130, Loss: 2.2941972771453876\n",
      "Accuracy 0.14\n",
      "Epoch 131, Loss: 2.2941654861776115\n",
      "Accuracy 0.14\n",
      "Epoch 132, Loss: 2.2941339946437362\n",
      "Accuracy 0.14\n",
      "Epoch 133, Loss: 2.2941027996040004\n",
      "Accuracy 0.14\n",
      "Epoch 134, Loss: 2.2940718978930765\n",
      "Accuracy 0.14\n",
      "Epoch 135, Loss: 2.2940412861099047\n",
      "Accuracy 0.14\n",
      "Epoch 136, Loss: 2.2940109610557684\n",
      "Accuracy 0.14\n",
      "Epoch 137, Loss: 2.2939809199684227\n",
      "Accuracy 0.14\n",
      "Epoch 138, Loss: 2.2939511596026123\n",
      "Accuracy 0.14\n",
      "Epoch 139, Loss: 2.2939216766636874\n",
      "Accuracy 0.14\n",
      "Epoch 140, Loss: 2.2938924690179245\n",
      "Accuracy 0.14\n",
      "Epoch 141, Loss: 2.2938635342743683\n",
      "Accuracy 0.14\n",
      "Epoch 142, Loss: 2.2938348688840895\n",
      "Accuracy 0.14\n",
      "Epoch 143, Loss: 2.293806468752907\n",
      "Accuracy 0.14\n",
      "Epoch 144, Loss: 2.293778331883964\n",
      "Accuracy 0.14\n",
      "Epoch 145, Loss: 2.2937504561008164\n",
      "Accuracy 0.14\n",
      "Epoch 146, Loss: 2.2937228373580636\n",
      "Accuracy 0.14\n",
      "Epoch 147, Loss: 2.29369547447171\n",
      "Accuracy 0.14\n",
      "Epoch 148, Loss: 2.2936683647898173\n",
      "Accuracy 0.14\n",
      "Epoch 149, Loss: 2.2936415056147985\n",
      "Accuracy 0.14\n",
      "Epoch 150, Loss: 2.2936148937383987\n",
      "Accuracy 0.14\n",
      "Epoch 151, Loss: 2.2935885264166402\n",
      "Accuracy 0.14\n",
      "Epoch 152, Loss: 2.29356240167085\n",
      "Accuracy 0.14\n",
      "Epoch 153, Loss: 2.2935365176674662\n",
      "Accuracy 0.14\n",
      "Epoch 154, Loss: 2.293510871085087\n",
      "Accuracy 0.14\n",
      "Epoch 155, Loss: 2.2934854596523797\n",
      "Accuracy 0.14\n",
      "Epoch 156, Loss: 2.2934602809504803\n",
      "Accuracy 0.14\n",
      "Epoch 157, Loss: 2.2934353322447913\n",
      "Accuracy 0.14\n",
      "Epoch 158, Loss: 2.293410610957505\n",
      "Accuracy 0.14\n",
      "Epoch 159, Loss: 2.293386114864836\n",
      "Accuracy 0.14\n",
      "Epoch 160, Loss: 2.2933618420900723\n",
      "Accuracy 0.14\n",
      "Epoch 161, Loss: 2.293337789105901\n",
      "Accuracy 0.14\n",
      "Epoch 162, Loss: 2.29331395400315\n",
      "Accuracy 0.14\n",
      "Epoch 163, Loss: 2.293290334332294\n",
      "Accuracy 0.14\n",
      "Epoch 164, Loss: 2.2932669285925438\n",
      "Accuracy 0.14\n",
      "Epoch 165, Loss: 2.293243733944383\n",
      "Accuracy 0.14\n",
      "Epoch 166, Loss: 2.29322074738719\n",
      "Accuracy 0.14\n",
      "Epoch 167, Loss: 2.2931979674524254\n",
      "Accuracy 0.14\n",
      "Epoch 168, Loss: 2.293175391298695\n",
      "Accuracy 0.14\n",
      "Epoch 169, Loss: 2.29315301726165\n",
      "Accuracy 0.14\n",
      "Epoch 170, Loss: 2.2931308430694832\n",
      "Accuracy 0.14\n",
      "Epoch 171, Loss: 2.293108865996971\n",
      "Accuracy 0.14\n",
      "Epoch 172, Loss: 2.293087084878022\n",
      "Accuracy 0.14\n",
      "Epoch 173, Loss: 2.293065497385545\n",
      "Accuracy 0.14\n",
      "Epoch 174, Loss: 2.2930441012611626\n",
      "Accuracy 0.14\n",
      "Epoch 175, Loss: 2.2930228946722675\n",
      "Accuracy 0.14\n",
      "Epoch 176, Loss: 2.2930018758600808\n",
      "Accuracy 0.14\n",
      "Epoch 177, Loss: 2.2929810424340165\n",
      "Accuracy 0.14\n",
      "Epoch 178, Loss: 2.2929603911726497\n",
      "Accuracy 0.14\n",
      "Epoch 179, Loss: 2.292939921304888\n",
      "Accuracy 0.14\n",
      "Epoch 180, Loss: 2.2929196309754425\n",
      "Accuracy 0.14\n",
      "Epoch 181, Loss: 2.2928995174344617\n",
      "Accuracy 0.14\n",
      "Epoch 182, Loss: 2.2928795795351733\n",
      "Accuracy 0.14\n",
      "Epoch 183, Loss: 2.2928598157552478\n",
      "Accuracy 0.14\n",
      "Epoch 184, Loss: 2.292840223243915\n",
      "Accuracy 0.14\n",
      "Epoch 185, Loss: 2.2928208008556665\n",
      "Accuracy 0.14\n",
      "Epoch 186, Loss: 2.2928015463570577\n",
      "Accuracy 0.14\n",
      "Epoch 187, Loss: 2.292782457567645\n",
      "Accuracy 0.14\n",
      "Epoch 188, Loss: 2.2927635334138716\n",
      "Accuracy 0.14\n",
      "Epoch 189, Loss: 2.292744771878099\n",
      "Accuracy 0.14\n",
      "Epoch 190, Loss: 2.2927261704616995\n",
      "Accuracy 0.14\n",
      "Epoch 191, Loss: 2.2927077280372705\n",
      "Accuracy 0.14\n",
      "Epoch 192, Loss: 2.2926894432187725\n",
      "Accuracy 0.14\n",
      "Epoch 193, Loss: 2.2926713143675714\n",
      "Accuracy 0.14\n",
      "Epoch 194, Loss: 2.29265333929932\n",
      "Accuracy 0.14\n",
      "Epoch 195, Loss: 2.2926355156215887\n",
      "Accuracy 0.14\n",
      "Epoch 196, Loss: 2.292617842583273\n",
      "Accuracy 0.14\n",
      "Epoch 197, Loss: 2.292600318548668\n",
      "Accuracy 0.14\n",
      "Epoch 198, Loss: 2.2925829420432167\n",
      "Accuracy 0.14\n",
      "Epoch 199, Loss: 2.2925657116842486\n",
      "Accuracy 0.14\n",
      "Epoch 200, Loss: 2.292548625658167\n",
      "Accuracy 0.14\n",
      "Epoch 201, Loss: 2.2925316822823323\n",
      "Accuracy 0.14\n",
      "Epoch 202, Loss: 2.2925148803357187\n",
      "Accuracy 0.14\n",
      "Epoch 203, Loss: 2.292498218124344\n",
      "Accuracy 0.14\n",
      "Epoch 204, Loss: 2.2924816938403603\n",
      "Accuracy 0.14\n",
      "Epoch 205, Loss: 2.2924653055890722\n",
      "Accuracy 0.14\n",
      "Epoch 206, Loss: 2.2924490517846268\n",
      "Accuracy 0.14\n",
      "Epoch 207, Loss: 2.292432930469032\n",
      "Accuracy 0.14\n",
      "Epoch 208, Loss: 2.2924169406893244\n",
      "Accuracy 0.14\n",
      "Epoch 209, Loss: 2.2924010809602895\n",
      "Accuracy 0.14\n",
      "Epoch 210, Loss: 2.2923853497268962\n",
      "Accuracy 0.14\n",
      "Epoch 211, Loss: 2.292369745057227\n",
      "Accuracy 0.14\n",
      "Epoch 212, Loss: 2.2923542659239584\n",
      "Accuracy 0.14\n",
      "Epoch 213, Loss: 2.292338911339995\n",
      "Accuracy 0.14\n",
      "Epoch 214, Loss: 2.2923236795163193\n",
      "Accuracy 0.14\n",
      "Epoch 215, Loss: 2.2923085685798914\n",
      "Accuracy 0.14\n",
      "Epoch 216, Loss: 2.2922935774843474\n",
      "Accuracy 0.14\n",
      "Epoch 217, Loss: 2.292278704825342\n",
      "Accuracy 0.14\n",
      "Epoch 218, Loss: 2.2922639496725097\n",
      "Accuracy 0.14\n",
      "Epoch 219, Loss: 2.292249311036524\n",
      "Accuracy 0.14\n",
      "Epoch 220, Loss: 2.2922347877209965\n",
      "Accuracy 0.14\n",
      "Epoch 221, Loss: 2.2922203786927704\n",
      "Accuracy 0.14\n",
      "Epoch 222, Loss: 2.2922060821615307\n",
      "Accuracy 0.14\n",
      "Epoch 223, Loss: 2.2921918959215875\n",
      "Accuracy 0.14\n",
      "Epoch 224, Loss: 2.292177819336576\n",
      "Accuracy 0.14\n",
      "Epoch 225, Loss: 2.2921638514517033\n",
      "Accuracy 0.14\n",
      "Epoch 226, Loss: 2.2921499911001564\n",
      "Accuracy 0.14\n",
      "Epoch 227, Loss: 2.29213623597751\n",
      "Accuracy 0.14\n",
      "Epoch 228, Loss: 2.292122585379354\n",
      "Accuracy 0.14\n",
      "Epoch 229, Loss: 2.2921090386894996\n",
      "Accuracy 0.14\n",
      "Epoch 230, Loss: 2.2920955936164735\n",
      "Accuracy 0.14\n",
      "Epoch 231, Loss: 2.2920822498455062\n",
      "Accuracy 0.14\n",
      "Epoch 232, Loss: 2.2920690057768023\n",
      "Accuracy 0.14\n",
      "Epoch 233, Loss: 2.2920558592946754\n",
      "Accuracy 0.14\n",
      "Epoch 234, Loss: 2.2920428104271307\n",
      "Accuracy 0.14\n",
      "Epoch 235, Loss: 2.2920298573764524\n",
      "Accuracy 0.14\n",
      "Epoch 236, Loss: 2.2920169996452873\n",
      "Accuracy 0.14\n",
      "Epoch 237, Loss: 2.292004235826041\n",
      "Accuracy 0.14\n",
      "Epoch 238, Loss: 2.2919915641143818\n",
      "Accuracy 0.14\n",
      "Epoch 239, Loss: 2.2919789837363744\n",
      "Accuracy 0.14\n",
      "Epoch 240, Loss: 2.291966493095726\n",
      "Accuracy 0.14\n",
      "Epoch 241, Loss: 2.291954091273721\n",
      "Accuracy 0.14\n",
      "Epoch 242, Loss: 2.291941777873755\n",
      "Accuracy 0.14\n",
      "Epoch 243, Loss: 2.2919295520164478\n",
      "Accuracy 0.14\n",
      "Epoch 244, Loss: 2.2919174122594357\n",
      "Accuracy 0.14\n",
      "Epoch 245, Loss: 2.291905358488244\n",
      "Accuracy 0.14\n",
      "Epoch 246, Loss: 2.2918933894282727\n",
      "Accuracy 0.14\n",
      "Epoch 247, Loss: 2.291881503765283\n",
      "Accuracy 0.14\n",
      "Epoch 248, Loss: 2.291869700786675\n",
      "Accuracy 0.14\n",
      "Epoch 249, Loss: 2.2918579789705573\n",
      "Accuracy 0.14\n",
      "Epoch 250, Loss: 2.291846337010423\n",
      "Accuracy 0.14\n",
      "Epoch 251, Loss: 2.2918347744989878\n",
      "Accuracy 0.14\n",
      "Epoch 252, Loss: 2.291823289409444\n",
      "Accuracy 0.14\n",
      "Epoch 253, Loss: 2.291811880621688\n",
      "Accuracy 0.14\n",
      "Epoch 254, Loss: 2.2918005481589017\n",
      "Accuracy 0.14\n",
      "Epoch 255, Loss: 2.291789290551142\n",
      "Accuracy 0.14\n",
      "Epoch 256, Loss: 2.2917781062818925\n",
      "Accuracy 0.14\n",
      "Epoch 257, Loss: 2.2917669955956073\n",
      "Accuracy 0.14\n",
      "Epoch 258, Loss: 2.2917559565529246\n",
      "Accuracy 0.14\n",
      "Epoch 259, Loss: 2.2917449896264905\n",
      "Accuracy 0.14\n",
      "Epoch 260, Loss: 2.291734093206669\n",
      "Accuracy 0.14\n",
      "Epoch 261, Loss: 2.2917232667235483\n",
      "Accuracy 0.14\n",
      "Epoch 262, Loss: 2.2917125097598756\n",
      "Accuracy 0.14\n",
      "Epoch 263, Loss: 2.291701821133179\n",
      "Accuracy 0.14\n",
      "Epoch 264, Loss: 2.29169119960273\n",
      "Accuracy 0.14\n",
      "Epoch 265, Loss: 2.291680644367892\n",
      "Accuracy 0.14\n",
      "Epoch 266, Loss: 2.291670155370108\n",
      "Accuracy 0.14\n",
      "Epoch 267, Loss: 2.2916597315073455\n",
      "Accuracy 0.14\n",
      "Epoch 268, Loss: 2.2916493717991067\n",
      "Accuracy 0.14\n",
      "Epoch 269, Loss: 2.291639075293025\n",
      "Accuracy 0.14\n",
      "Epoch 270, Loss: 2.291628841703984\n",
      "Accuracy 0.14\n",
      "Epoch 271, Loss: 2.2916186695201777\n",
      "Accuracy 0.14\n",
      "Epoch 272, Loss: 2.2916085581048082\n",
      "Accuracy 0.14\n",
      "Epoch 273, Loss: 2.29159850652832\n",
      "Accuracy 0.14\n",
      "Epoch 274, Loss: 2.2915885136441085\n",
      "Accuracy 0.14\n",
      "Epoch 275, Loss: 2.291578578716698\n",
      "Accuracy 0.14\n",
      "Epoch 276, Loss: 2.291568701113355\n",
      "Accuracy 0.14\n",
      "Epoch 277, Loss: 2.2915588803608817\n",
      "Accuracy 0.14\n",
      "Epoch 278, Loss: 2.291549116258152\n",
      "Accuracy 0.14\n",
      "Epoch 279, Loss: 2.291539407302738\n",
      "Accuracy 0.14\n",
      "Epoch 280, Loss: 2.291529752149102\n",
      "Accuracy 0.14\n",
      "Epoch 281, Loss: 2.291520150226511\n",
      "Accuracy 0.14\n",
      "Epoch 282, Loss: 2.2915106009607764\n",
      "Accuracy 0.14\n",
      "Epoch 283, Loss: 2.291501104875071\n",
      "Accuracy 0.14\n",
      "Epoch 284, Loss: 2.2914916596546964\n",
      "Accuracy 0.14\n",
      "Epoch 285, Loss: 2.291482264947203\n",
      "Accuracy 0.14\n",
      "Epoch 286, Loss: 2.291472920249578\n",
      "Accuracy 0.14\n",
      "Epoch 287, Loss: 2.291463623370331\n",
      "Accuracy 0.14\n",
      "Epoch 288, Loss: 2.29145437436467\n",
      "Accuracy 0.14\n",
      "Epoch 289, Loss: 2.2914451735400356\n",
      "Accuracy 0.14\n",
      "Epoch 290, Loss: 2.2914360197714934\n",
      "Accuracy 0.14\n",
      "Epoch 291, Loss: 2.2914269116860497\n",
      "Accuracy 0.14\n",
      "Epoch 292, Loss: 2.2914178482993792\n",
      "Accuracy 0.14\n",
      "Epoch 293, Loss: 2.2914088293876214\n",
      "Accuracy 0.14\n",
      "Epoch 294, Loss: 2.2913998547203995\n",
      "Accuracy 0.14\n",
      "Epoch 295, Loss: 2.2913909234524477\n",
      "Accuracy 0.14\n",
      "Epoch 296, Loss: 2.291382035094067\n",
      "Accuracy 0.14\n",
      "Epoch 297, Loss: 2.2913731890990183\n",
      "Accuracy 0.14\n",
      "Epoch 298, Loss: 2.2913643825944363\n",
      "Accuracy 0.14\n",
      "Epoch 299, Loss: 2.291355616834558\n",
      "Accuracy 0.14\n",
      "Epoch 300, Loss: 2.2913468910462997\n",
      "Accuracy 0.14\n",
      "Epoch 301, Loss: 2.2913382037580314\n",
      "Accuracy 0.14\n",
      "Epoch 302, Loss: 2.2913295550212087\n",
      "Accuracy 0.14\n",
      "Epoch 303, Loss: 2.2913209454017927\n",
      "Accuracy 0.14\n",
      "Epoch 304, Loss: 2.291312374222076\n",
      "Accuracy 0.14\n",
      "Epoch 305, Loss: 2.2913038401005474\n",
      "Accuracy 0.14\n",
      "Epoch 306, Loss: 2.2912953418480466\n",
      "Accuracy 0.14\n",
      "Epoch 307, Loss: 2.2912868797638617\n",
      "Accuracy 0.14\n",
      "Epoch 308, Loss: 2.2912784529309937\n",
      "Accuracy 0.14\n",
      "Epoch 309, Loss: 2.2912700623467672\n",
      "Accuracy 0.14\n",
      "Epoch 310, Loss: 2.291261706684727\n",
      "Accuracy 0.14\n",
      "Epoch 311, Loss: 2.291253384111473\n",
      "Accuracy 0.14\n",
      "Epoch 312, Loss: 2.2912450948045286\n",
      "Accuracy 0.14\n",
      "Epoch 313, Loss: 2.291236838321747\n",
      "Accuracy 0.14\n",
      "Epoch 314, Loss: 2.2912286133155657\n",
      "Accuracy 0.14\n",
      "Epoch 315, Loss: 2.291220418811983\n",
      "Accuracy 0.14\n",
      "Epoch 316, Loss: 2.2912122536441566\n",
      "Accuracy 0.14\n",
      "Epoch 317, Loss: 2.2912041190565895\n",
      "Accuracy 0.14\n",
      "Epoch 318, Loss: 2.291196013252199\n",
      "Accuracy 0.14\n",
      "Epoch 319, Loss: 2.2911879359208025\n",
      "Accuracy 0.14\n",
      "Epoch 320, Loss: 2.2911798860625496\n",
      "Accuracy 0.14\n",
      "Epoch 321, Loss: 2.29117186303077\n",
      "Accuracy 0.14\n",
      "Epoch 322, Loss: 2.291163866696458\n",
      "Accuracy 0.14\n",
      "Epoch 323, Loss: 2.2911558963921514\n",
      "Accuracy 0.14\n",
      "Epoch 324, Loss: 2.291147951301681\n",
      "Accuracy 0.14\n",
      "Epoch 325, Loss: 2.291140031582379\n",
      "Accuracy 0.14\n",
      "Epoch 326, Loss: 2.2911321367410205\n",
      "Accuracy 0.14\n",
      "Epoch 327, Loss: 2.291124266932723\n",
      "Accuracy 0.14\n",
      "Epoch 328, Loss: 2.2911164208119654\n",
      "Accuracy 0.14\n",
      "Epoch 329, Loss: 2.2911085978245147\n",
      "Accuracy 0.14\n",
      "Epoch 330, Loss: 2.291100797419295\n",
      "Accuracy 0.14\n",
      "Epoch 331, Loss: 2.29109301902132\n",
      "Accuracy 0.14\n",
      "Epoch 332, Loss: 2.2910852618932838\n",
      "Accuracy 0.14\n",
      "Epoch 333, Loss: 2.2910775260206995\n",
      "Accuracy 0.14\n",
      "Epoch 334, Loss: 2.2910698103005274\n",
      "Accuracy 0.14\n",
      "Epoch 335, Loss: 2.291062114732679\n",
      "Accuracy 0.14\n",
      "Epoch 336, Loss: 2.291054439142088\n",
      "Accuracy 0.14\n",
      "Epoch 337, Loss: 2.291046782081853\n",
      "Accuracy 0.14\n",
      "Epoch 338, Loss: 2.2910391434307895\n",
      "Accuracy 0.14\n",
      "Epoch 339, Loss: 2.291031522475977\n",
      "Accuracy 0.14\n",
      "Epoch 340, Loss: 2.29102391823066\n",
      "Accuracy 0.14\n",
      "Epoch 341, Loss: 2.291016330357683\n",
      "Accuracy 0.14\n",
      "Epoch 342, Loss: 2.291008759545035\n",
      "Accuracy 0.14\n",
      "Epoch 343, Loss: 2.291001204172416\n",
      "Accuracy 0.14\n",
      "Epoch 344, Loss: 2.2909936645100153\n",
      "Accuracy 0.14\n",
      "Epoch 345, Loss: 2.290986140751981\n",
      "Accuracy 0.14\n",
      "Epoch 346, Loss: 2.2909786318910945\n",
      "Accuracy 0.14\n",
      "Epoch 347, Loss: 2.290971136471542\n",
      "Accuracy 0.14\n",
      "Epoch 348, Loss: 2.2909636553437185\n",
      "Accuracy 0.14\n",
      "Epoch 349, Loss: 2.290956188604592\n",
      "Accuracy 0.14\n",
      "Epoch 350, Loss: 2.2909487359339744\n",
      "Accuracy 0.14\n",
      "Epoch 351, Loss: 2.2909412973778127\n",
      "Accuracy 0.14\n",
      "Epoch 352, Loss: 2.2909338704464055\n",
      "Accuracy 0.14\n",
      "Epoch 353, Loss: 2.290926455823604\n",
      "Accuracy 0.14\n",
      "Epoch 354, Loss: 2.290919052188663\n",
      "Accuracy 0.14\n",
      "Epoch 355, Loss: 2.2909116589302148\n",
      "Accuracy 0.14\n",
      "Epoch 356, Loss: 2.2909042760208544\n",
      "Accuracy 0.14\n",
      "Epoch 357, Loss: 2.290896902422884\n",
      "Accuracy 0.14\n",
      "Epoch 358, Loss: 2.290889537824639\n",
      "Accuracy 0.14\n",
      "Epoch 359, Loss: 2.290882182941716\n",
      "Accuracy 0.14\n",
      "Epoch 360, Loss: 2.290874837138229\n",
      "Accuracy 0.14\n",
      "Epoch 361, Loss: 2.2908674986107993\n",
      "Accuracy 0.14\n",
      "Epoch 362, Loss: 2.290860168294868\n",
      "Accuracy 0.14\n",
      "Epoch 363, Loss: 2.290852845651881\n",
      "Accuracy 0.14\n",
      "Epoch 364, Loss: 2.2908455294561185\n",
      "Accuracy 0.14\n",
      "Epoch 365, Loss: 2.2908382188915293\n",
      "Accuracy 0.14\n",
      "Epoch 366, Loss: 2.290830913762399\n",
      "Accuracy 0.14\n",
      "Epoch 367, Loss: 2.290823613208291\n",
      "Accuracy 0.14\n",
      "Epoch 368, Loss: 2.290816317851318\n",
      "Accuracy 0.14\n",
      "Epoch 369, Loss: 2.290809026930049\n",
      "Accuracy 0.14\n",
      "Epoch 370, Loss: 2.290801738848395\n",
      "Accuracy 0.14\n",
      "Epoch 371, Loss: 2.290794453479839\n",
      "Accuracy 0.14\n",
      "Epoch 372, Loss: 2.2907871711083105\n",
      "Accuracy 0.14\n",
      "Epoch 373, Loss: 2.290779892839525\n",
      "Accuracy 0.14\n",
      "Epoch 374, Loss: 2.290772616907652\n",
      "Accuracy 0.14\n",
      "Epoch 375, Loss: 2.290765343339127\n",
      "Accuracy 0.14\n",
      "Epoch 376, Loss: 2.290758070881251\n",
      "Accuracy 0.14\n",
      "Epoch 377, Loss: 2.2907507991842757\n",
      "Accuracy 0.14\n",
      "Epoch 378, Loss: 2.2907435268342065\n",
      "Accuracy 0.14\n",
      "Epoch 379, Loss: 2.2907362547921295\n",
      "Accuracy 0.14\n",
      "Epoch 380, Loss: 2.2907289816633103\n",
      "Accuracy 0.14\n",
      "Epoch 381, Loss: 2.2907217064188385\n",
      "Accuracy 0.14\n",
      "Epoch 382, Loss: 2.2907144284994585\n",
      "Accuracy 0.14\n",
      "Epoch 383, Loss: 2.290707148119908\n",
      "Accuracy 0.14\n",
      "Epoch 384, Loss: 2.290699863484838\n",
      "Accuracy 0.14\n",
      "Epoch 385, Loss: 2.2906925762182433\n",
      "Accuracy 0.14\n",
      "Epoch 386, Loss: 2.2906852854145123\n",
      "Accuracy 0.14\n",
      "Epoch 387, Loss: 2.2906779919371276\n",
      "Accuracy 0.14\n",
      "Epoch 388, Loss: 2.2906706956937994\n",
      "Accuracy 0.14\n",
      "Epoch 389, Loss: 2.290663396172579\n",
      "Accuracy 0.14\n",
      "Epoch 390, Loss: 2.2906560915883065\n",
      "Accuracy 0.14\n",
      "Epoch 391, Loss: 2.2906487822721973\n",
      "Accuracy 0.14\n",
      "Epoch 392, Loss: 2.2906414679944347\n",
      "Accuracy 0.14\n",
      "Epoch 393, Loss: 2.290634148859475\n",
      "Accuracy 0.14\n",
      "Epoch 394, Loss: 2.290626824445632\n",
      "Accuracy 0.14\n",
      "Epoch 395, Loss: 2.2906194938253646\n",
      "Accuracy 0.14\n",
      "Epoch 396, Loss: 2.290612156214963\n",
      "Accuracy 0.14\n",
      "Epoch 397, Loss: 2.2906048107600365\n",
      "Accuracy 0.14\n",
      "Epoch 398, Loss: 2.2905974576995725\n",
      "Accuracy 0.14\n",
      "Epoch 399, Loss: 2.2905900951045473\n",
      "Accuracy 0.14\n",
      "Epoch 400, Loss: 2.2905827238872756\n",
      "Accuracy 0.14\n",
      "Epoch 401, Loss: 2.2905753428006865\n",
      "Accuracy 0.14\n",
      "Epoch 402, Loss: 2.290567953163918\n",
      "Accuracy 0.14\n",
      "Epoch 403, Loss: 2.290560553541027\n",
      "Accuracy 0.14\n",
      "Epoch 404, Loss: 2.2905531425763197\n",
      "Accuracy 0.14\n",
      "Epoch 405, Loss: 2.2905457210847016\n",
      "Accuracy 0.14\n",
      "Epoch 406, Loss: 2.2905382884277223\n",
      "Accuracy 0.14\n",
      "Epoch 407, Loss: 2.290530844596954\n",
      "Accuracy 0.14\n",
      "Epoch 408, Loss: 2.290523390302342\n",
      "Accuracy 0.14\n",
      "Epoch 409, Loss: 2.2905159251299447\n",
      "Accuracy 0.14\n",
      "Epoch 410, Loss: 2.290508447668739\n",
      "Accuracy 0.14\n",
      "Epoch 411, Loss: 2.2905009550126687\n",
      "Accuracy 0.14\n",
      "Epoch 412, Loss: 2.290493447312227\n",
      "Accuracy 0.14\n",
      "Epoch 413, Loss: 2.2904859253129297\n",
      "Accuracy 0.14\n",
      "Epoch 414, Loss: 2.2904783878666604\n",
      "Accuracy 0.14\n",
      "Epoch 415, Loss: 2.2904708347811833\n",
      "Accuracy 0.14\n",
      "Epoch 416, Loss: 2.2904632665215967\n",
      "Accuracy 0.14\n",
      "Epoch 417, Loss: 2.290455681500524\n",
      "Accuracy 0.14\n",
      "Epoch 418, Loss: 2.290448081101461\n",
      "Accuracy 0.14\n",
      "Epoch 419, Loss: 2.290440463443474\n",
      "Accuracy 0.14\n",
      "Epoch 420, Loss: 2.2904328292905647\n",
      "Accuracy 0.14\n",
      "Epoch 421, Loss: 2.29042517736878\n",
      "Accuracy 0.14\n",
      "Epoch 422, Loss: 2.2904175069685824\n",
      "Accuracy 0.14\n",
      "Epoch 423, Loss: 2.2904098180897137\n",
      "Accuracy 0.14\n",
      "Epoch 424, Loss: 2.2904021112239334\n",
      "Accuracy 0.14\n",
      "Epoch 425, Loss: 2.290394384833088\n",
      "Accuracy 0.14\n",
      "Epoch 426, Loss: 2.2903866378388438\n",
      "Accuracy 0.14\n",
      "Epoch 427, Loss: 2.2903788695860716\n",
      "Accuracy 0.14\n",
      "Epoch 428, Loss: 2.290371080280077\n",
      "Accuracy 0.14\n",
      "Epoch 429, Loss: 2.290363268032582\n",
      "Accuracy 0.14\n",
      "Epoch 430, Loss: 2.290355434616344\n",
      "Accuracy 0.14\n",
      "Epoch 431, Loss: 2.290347579312658\n",
      "Accuracy 0.14\n",
      "Epoch 432, Loss: 2.290339701854267\n",
      "Accuracy 0.14\n",
      "Epoch 433, Loss: 2.290331800954743\n",
      "Accuracy 0.14\n",
      "Epoch 434, Loss: 2.2903238762531264\n",
      "Accuracy 0.14\n",
      "Epoch 435, Loss: 2.290315927850244\n",
      "Accuracy 0.14\n",
      "Epoch 436, Loss: 2.2903079545597356\n",
      "Accuracy 0.14\n",
      "Epoch 437, Loss: 2.290299955613241\n",
      "Accuracy 0.14\n",
      "Epoch 438, Loss: 2.2902919289910733\n",
      "Accuracy 0.14\n",
      "Epoch 439, Loss: 2.2902838749442824\n",
      "Accuracy 0.14\n",
      "Epoch 440, Loss: 2.29027579446018\n",
      "Accuracy 0.14\n",
      "Epoch 441, Loss: 2.290267686730777\n",
      "Accuracy 0.14\n",
      "Epoch 442, Loss: 2.2902595522077065\n",
      "Accuracy 0.14\n",
      "Epoch 443, Loss: 2.2902513860263953\n",
      "Accuracy 0.14\n",
      "Epoch 444, Loss: 2.290243191618279\n",
      "Accuracy 0.14\n",
      "Epoch 445, Loss: 2.290234966161235\n",
      "Accuracy 0.14\n",
      "Epoch 446, Loss: 2.29022671065081\n",
      "Accuracy 0.14\n",
      "Epoch 447, Loss: 2.2902184249713535\n",
      "Accuracy 0.14\n",
      "Epoch 448, Loss: 2.2902101100078265\n",
      "Accuracy 0.14\n",
      "Epoch 449, Loss: 2.2902017644176813\n",
      "Accuracy 0.14\n",
      "Epoch 450, Loss: 2.2901933884815735\n",
      "Accuracy 0.14\n",
      "Epoch 451, Loss: 2.2901849818420144\n",
      "Accuracy 0.14\n",
      "Epoch 452, Loss: 2.290176542987852\n",
      "Accuracy 0.14\n",
      "Epoch 453, Loss: 2.2901680712570154\n",
      "Accuracy 0.14\n",
      "Epoch 454, Loss: 2.290159565898765\n",
      "Accuracy 0.14\n",
      "Epoch 455, Loss: 2.290151027883985\n",
      "Accuracy 0.14\n",
      "Epoch 456, Loss: 2.2901424555150345\n",
      "Accuracy 0.14\n",
      "Epoch 457, Loss: 2.290133850006325\n",
      "Accuracy 0.14\n",
      "Epoch 458, Loss: 2.2901252094300517\n",
      "Accuracy 0.14\n",
      "Epoch 459, Loss: 2.2901165341779977\n",
      "Accuracy 0.14\n",
      "Epoch 460, Loss: 2.2901078231559726\n",
      "Accuracy 0.14\n",
      "Epoch 461, Loss: 2.290099076520521\n",
      "Accuracy 0.14\n",
      "Epoch 462, Loss: 2.2900902921246433\n",
      "Accuracy 0.14\n",
      "Epoch 463, Loss: 2.2900814691896807\n",
      "Accuracy 0.14\n",
      "Epoch 464, Loss: 2.290072609070363\n",
      "Accuracy 0.14\n",
      "Epoch 465, Loss: 2.2900637094324185\n",
      "Accuracy 0.14\n",
      "Epoch 466, Loss: 2.2900547682116885\n",
      "Accuracy 0.14\n",
      "Epoch 467, Loss: 2.290045787046453\n",
      "Accuracy 0.14\n",
      "Epoch 468, Loss: 2.2900367667786075\n",
      "Accuracy 0.14\n",
      "Epoch 469, Loss: 2.2900277070713693\n",
      "Accuracy 0.14\n",
      "Epoch 470, Loss: 2.290018608755437\n",
      "Accuracy 0.14\n",
      "Epoch 471, Loss: 2.2900094695594624\n",
      "Accuracy 0.14\n",
      "Epoch 472, Loss: 2.290000286379857\n",
      "Accuracy 0.14\n",
      "Epoch 473, Loss: 2.2899910578079403\n",
      "Accuracy 0.14\n",
      "Epoch 474, Loss: 2.28998178640814\n",
      "Accuracy 0.14\n",
      "Epoch 475, Loss: 2.2899724702191153\n",
      "Accuracy 0.14\n",
      "Epoch 476, Loss: 2.2899631090870307\n",
      "Accuracy 0.14\n",
      "Epoch 477, Loss: 2.28995370270805\n",
      "Accuracy 0.14\n",
      "Epoch 478, Loss: 2.289944251267683\n",
      "Accuracy 0.14\n",
      "Epoch 479, Loss: 2.2899347528211456\n",
      "Accuracy 0.14\n",
      "Epoch 480, Loss: 2.289925207811648\n",
      "Accuracy 0.14\n",
      "Epoch 481, Loss: 2.2899156158529523\n",
      "Accuracy 0.14\n",
      "Epoch 482, Loss: 2.2899059759200844\n",
      "Accuracy 0.14\n",
      "Epoch 483, Loss: 2.2898962873743476\n",
      "Accuracy 0.14\n",
      "Epoch 484, Loss: 2.289886548754251\n",
      "Accuracy 0.14\n",
      "Epoch 485, Loss: 2.289876760736467\n",
      "Accuracy 0.14\n",
      "Epoch 486, Loss: 2.2898669216099314\n",
      "Accuracy 0.14\n",
      "Epoch 487, Loss: 2.2898570319999787\n",
      "Accuracy 0.14\n",
      "Epoch 488, Loss: 2.289847090868297\n",
      "Accuracy 0.14\n",
      "Epoch 489, Loss: 2.289837096904145\n",
      "Accuracy 0.14\n",
      "Epoch 490, Loss: 2.2898270492007935\n",
      "Accuracy 0.14\n",
      "Epoch 491, Loss: 2.2898169469023455\n",
      "Accuracy 0.14\n",
      "Epoch 492, Loss: 2.289806790439139\n",
      "Accuracy 0.14\n",
      "Epoch 493, Loss: 2.2897965788537253\n",
      "Accuracy 0.14\n",
      "Epoch 494, Loss: 2.2897863128850657\n",
      "Accuracy 0.14\n",
      "Epoch 495, Loss: 2.289775990706422\n",
      "Accuracy 0.14\n",
      "Epoch 496, Loss: 2.289765613049712\n",
      "Accuracy 0.14\n",
      "Epoch 497, Loss: 2.2897551777876095\n",
      "Accuracy 0.14\n",
      "Epoch 498, Loss: 2.2897446839154973\n",
      "Accuracy 0.14\n",
      "Epoch 499, Loss: 2.2897341293250464\n",
      "Accuracy 0.14\n",
      "Epoch 500, Loss: 2.289723515128424\n",
      "Accuracy 0.14\n",
      "Epoch 501, Loss: 2.2897128404556755\n",
      "Accuracy 0.14\n",
      "Epoch 502, Loss: 2.2897021039763477\n",
      "Accuracy 0.14\n",
      "Epoch 503, Loss: 2.2896913043872638\n",
      "Accuracy 0.14\n",
      "Epoch 504, Loss: 2.289680440756568\n",
      "Accuracy 0.14\n",
      "Epoch 505, Loss: 2.28966951426552\n",
      "Accuracy 0.14\n",
      "Epoch 506, Loss: 2.2896585257656663\n",
      "Accuracy 0.14\n",
      "Epoch 507, Loss: 2.2896474728028284\n",
      "Accuracy 0.14\n",
      "Epoch 508, Loss: 2.2896363554309773\n",
      "Accuracy 0.14\n",
      "Epoch 509, Loss: 2.289625170078643\n",
      "Accuracy 0.14\n",
      "Epoch 510, Loss: 2.2896139182609385\n",
      "Accuracy 0.14\n",
      "Epoch 511, Loss: 2.2896025982029986\n",
      "Accuracy 0.14\n",
      "Epoch 512, Loss: 2.2895912087210477\n",
      "Accuracy 0.14\n",
      "Epoch 513, Loss: 2.289579750242648\n",
      "Accuracy 0.14\n",
      "Epoch 514, Loss: 2.2895682208963954\n",
      "Accuracy 0.14\n",
      "Epoch 515, Loss: 2.289556621274244\n",
      "Accuracy 0.14\n",
      "Epoch 516, Loss: 2.289544950459815\n",
      "Accuracy 0.14\n",
      "Epoch 517, Loss: 2.2895332076115773\n",
      "Accuracy 0.14\n",
      "Epoch 518, Loss: 2.2895213910553083\n",
      "Accuracy 0.14\n",
      "Epoch 519, Loss: 2.2895095000348435\n",
      "Accuracy 0.14\n",
      "Epoch 520, Loss: 2.2894975373676107\n",
      "Accuracy 0.14\n",
      "Epoch 521, Loss: 2.2894854996487313\n",
      "Accuracy 0.14\n",
      "Epoch 522, Loss: 2.2894733838309578\n",
      "Accuracy 0.14\n",
      "Epoch 523, Loss: 2.2894611889625907\n",
      "Accuracy 0.14\n",
      "Epoch 524, Loss: 2.2894489135936693\n",
      "Accuracy 0.14\n",
      "Epoch 525, Loss: 2.2894365581875364\n",
      "Accuracy 0.14\n",
      "Epoch 526, Loss: 2.289424122169198\n",
      "Accuracy 0.14\n",
      "Epoch 527, Loss: 2.2894116030171126\n",
      "Accuracy 0.14\n",
      "Epoch 528, Loss: 2.289399001002479\n",
      "Accuracy 0.14\n",
      "Epoch 529, Loss: 2.289386317431952\n",
      "Accuracy 0.14\n",
      "Epoch 530, Loss: 2.2893735494836776\n",
      "Accuracy 0.14\n",
      "Epoch 531, Loss: 2.289360696430931\n",
      "Accuracy 0.14\n",
      "Epoch 532, Loss: 2.2893477573369267\n",
      "Accuracy 0.14\n",
      "Epoch 533, Loss: 2.2893347297966002\n",
      "Accuracy 0.14\n",
      "Epoch 534, Loss: 2.2893216143726076\n",
      "Accuracy 0.14\n",
      "Epoch 535, Loss: 2.2893084073205876\n",
      "Accuracy 0.14\n",
      "Epoch 536, Loss: 2.2892951095545073\n",
      "Accuracy 0.14\n",
      "Epoch 537, Loss: 2.2892817225841657\n",
      "Accuracy 0.14\n",
      "Epoch 538, Loss: 2.2892682458259324\n",
      "Accuracy 0.14\n",
      "Epoch 539, Loss: 2.289254675910689\n",
      "Accuracy 0.14\n",
      "Epoch 540, Loss: 2.289241012255273\n",
      "Accuracy 0.14\n",
      "Epoch 541, Loss: 2.2892272515496606\n",
      "Accuracy 0.14\n",
      "Epoch 542, Loss: 2.289213394083701\n",
      "Accuracy 0.14\n",
      "Epoch 543, Loss: 2.2891994388443635\n",
      "Accuracy 0.14\n",
      "Epoch 544, Loss: 2.289185385604404\n",
      "Accuracy 0.14\n",
      "Epoch 545, Loss: 2.2891712321112765\n",
      "Accuracy 0.14\n",
      "Epoch 546, Loss: 2.2891569767793607\n",
      "Accuracy 0.14\n",
      "Epoch 547, Loss: 2.28914262027268\n",
      "Accuracy 0.14\n",
      "Epoch 548, Loss: 2.2891281603991884\n",
      "Accuracy 0.14\n",
      "Epoch 549, Loss: 2.2891135945773056\n",
      "Accuracy 0.14\n",
      "Epoch 550, Loss: 2.2890989228680754\n",
      "Accuracy 0.14\n",
      "Epoch 551, Loss: 2.2890841444974974\n",
      "Accuracy 0.14\n",
      "Epoch 552, Loss: 2.2890692582723573\n",
      "Accuracy 0.14\n",
      "Epoch 553, Loss: 2.2890542630093496\n",
      "Accuracy 0.14\n",
      "Epoch 554, Loss: 2.289039156639854\n",
      "Accuracy 0.14\n",
      "Epoch 555, Loss: 2.289023937129604\n",
      "Accuracy 0.14\n",
      "Epoch 556, Loss: 2.2890086018178444\n",
      "Accuracy 0.14\n",
      "Epoch 557, Loss: 2.288993153353728\n",
      "Accuracy 0.14\n",
      "Epoch 558, Loss: 2.288977588480347\n",
      "Accuracy 0.14\n",
      "Epoch 559, Loss: 2.2889619063874354\n",
      "Accuracy 0.14\n",
      "Epoch 560, Loss: 2.288946104605454\n",
      "Accuracy 0.14\n",
      "Epoch 561, Loss: 2.2889301845133985\n",
      "Accuracy 0.14\n",
      "Epoch 562, Loss: 2.2889141436615246\n",
      "Accuracy 0.14\n",
      "Epoch 563, Loss: 2.2888979807503906\n",
      "Accuracy 0.14\n",
      "Epoch 564, Loss: 2.2888816941847434\n",
      "Accuracy 0.14\n",
      "Epoch 565, Loss: 2.2888652807527934\n",
      "Accuracy 0.14\n",
      "Epoch 566, Loss: 2.288848742404337\n",
      "Accuracy 0.14\n",
      "Epoch 567, Loss: 2.2888320772909982\n",
      "Accuracy 0.14\n",
      "Epoch 568, Loss: 2.2888152826813988\n",
      "Accuracy 0.14\n",
      "Epoch 569, Loss: 2.288798354417572\n",
      "Accuracy 0.14\n",
      "Epoch 570, Loss: 2.2887812918129304\n",
      "Accuracy 0.14\n",
      "Epoch 571, Loss: 2.288764096325692\n",
      "Accuracy 0.14\n",
      "Epoch 572, Loss: 2.288746762479011\n",
      "Accuracy 0.14\n",
      "Epoch 573, Loss: 2.288729289864171\n",
      "Accuracy 0.14\n",
      "Epoch 574, Loss: 2.288711677025315\n",
      "Accuracy 0.14\n",
      "Epoch 575, Loss: 2.2886939256778214\n",
      "Accuracy 0.14\n",
      "Epoch 576, Loss: 2.2886760295820467\n",
      "Accuracy 0.14\n",
      "Epoch 577, Loss: 2.2886579871517205\n",
      "Accuracy 0.14\n",
      "Epoch 578, Loss: 2.2886397989937897\n",
      "Accuracy 0.14\n",
      "Epoch 579, Loss: 2.288621463499171\n",
      "Accuracy 0.14\n",
      "Epoch 580, Loss: 2.288602976105602\n",
      "Accuracy 0.14\n",
      "Epoch 581, Loss: 2.288584333423892\n",
      "Accuracy 0.14\n",
      "Epoch 582, Loss: 2.2885655361650357\n",
      "Accuracy 0.14\n",
      "Epoch 583, Loss: 2.2885465845989637\n",
      "Accuracy 0.14\n",
      "Epoch 584, Loss: 2.288527474969953\n",
      "Accuracy 0.14\n",
      "Epoch 585, Loss: 2.288508205423078\n",
      "Accuracy 0.14\n",
      "Epoch 586, Loss: 2.288488776107667\n",
      "Accuracy 0.14\n",
      "Epoch 587, Loss: 2.288469178683021\n",
      "Accuracy 0.14\n",
      "Epoch 588, Loss: 2.2884494109492644\n",
      "Accuracy 0.14\n",
      "Epoch 589, Loss: 2.288429471614771\n",
      "Accuracy 0.14\n",
      "Epoch 590, Loss: 2.2884093633523532\n",
      "Accuracy 0.14\n",
      "Epoch 591, Loss: 2.2883890818928374\n",
      "Accuracy 0.14\n",
      "Epoch 592, Loss: 2.2883686238924237\n",
      "Accuracy 0.14\n",
      "Epoch 593, Loss: 2.288347989131082\n",
      "Accuracy 0.14\n",
      "Epoch 594, Loss: 2.288327176123027\n",
      "Accuracy 0.14\n",
      "Epoch 595, Loss: 2.288306184163723\n",
      "Accuracy 0.14\n",
      "Epoch 596, Loss: 2.288285010700394\n",
      "Accuracy 0.14\n",
      "Epoch 597, Loss: 2.288263650825331\n",
      "Accuracy 0.14\n",
      "Epoch 598, Loss: 2.2882421023177493\n",
      "Accuracy 0.14\n",
      "Epoch 599, Loss: 2.2882203637343483\n",
      "Accuracy 0.14\n",
      "Epoch 600, Loss: 2.288198433910294\n",
      "Accuracy 0.14\n",
      "Epoch 601, Loss: 2.2881763086546925\n",
      "Accuracy 0.14\n",
      "Epoch 602, Loss: 2.288153982372302\n",
      "Accuracy 0.14\n",
      "Epoch 603, Loss: 2.2881314546698306\n",
      "Accuracy 0.14\n",
      "Epoch 604, Loss: 2.2881087259651247\n",
      "Accuracy 0.14\n",
      "Epoch 605, Loss: 2.28808579354064\n",
      "Accuracy 0.14\n",
      "Epoch 606, Loss: 2.2880626567260043\n",
      "Accuracy 0.14\n",
      "Epoch 607, Loss: 2.288039312398194\n",
      "Accuracy 0.14\n",
      "Epoch 608, Loss: 2.288015750515674\n",
      "Accuracy 0.14\n",
      "Epoch 609, Loss: 2.2879919694489055\n",
      "Accuracy 0.14\n",
      "Epoch 610, Loss: 2.2879679683279446\n",
      "Accuracy 0.14\n",
      "Epoch 611, Loss: 2.28794374574804\n",
      "Accuracy 0.14\n",
      "Epoch 612, Loss: 2.287919298817331\n",
      "Accuracy 0.14\n",
      "Epoch 613, Loss: 2.287894628337427\n",
      "Accuracy 0.14\n",
      "Epoch 614, Loss: 2.2878697306071185\n",
      "Accuracy 0.14\n",
      "Epoch 615, Loss: 2.2878445982979927\n",
      "Accuracy 0.14\n",
      "Epoch 616, Loss: 2.287819231152208\n",
      "Accuracy 0.14\n",
      "Epoch 617, Loss: 2.2877936222018924\n",
      "Accuracy 0.14\n",
      "Epoch 618, Loss: 2.287767768859041\n",
      "Accuracy 0.14\n",
      "Epoch 619, Loss: 2.287741671315824\n",
      "Accuracy 0.14\n",
      "Epoch 620, Loss: 2.287715328591003\n",
      "Accuracy 0.14\n",
      "Epoch 621, Loss: 2.2876887382144986\n",
      "Accuracy 0.14\n",
      "Epoch 622, Loss: 2.287661895305398\n",
      "Accuracy 0.14\n",
      "Epoch 623, Loss: 2.2876347953246023\n",
      "Accuracy 0.14\n",
      "Epoch 624, Loss: 2.2876074355593343\n",
      "Accuracy 0.14\n",
      "Epoch 625, Loss: 2.287579810691761\n",
      "Accuracy 0.14\n",
      "Epoch 626, Loss: 2.287551916911024\n",
      "Accuracy 0.14\n",
      "Epoch 627, Loss: 2.287523752834535\n",
      "Accuracy 0.14\n",
      "Epoch 628, Loss: 2.287495316143457\n",
      "Accuracy 0.14\n",
      "Epoch 629, Loss: 2.287466602261963\n",
      "Accuracy 0.14\n",
      "Epoch 630, Loss: 2.2874376009910713\n",
      "Accuracy 0.14\n",
      "Epoch 631, Loss: 2.2874083081726586\n",
      "Accuracy 0.14\n",
      "Epoch 632, Loss: 2.287378720815251\n",
      "Accuracy 0.14\n",
      "Epoch 633, Loss: 2.2873488406556426\n",
      "Accuracy 0.14\n",
      "Epoch 634, Loss: 2.2873186637728513\n",
      "Accuracy 0.14\n",
      "Epoch 635, Loss: 2.287288185624799\n",
      "Accuracy 0.14\n",
      "Epoch 636, Loss: 2.287257401590766\n",
      "Accuracy 0.14\n",
      "Epoch 637, Loss: 2.287226305659885\n",
      "Accuracy 0.14\n",
      "Epoch 638, Loss: 2.287194893181002\n",
      "Accuracy 0.14\n",
      "Epoch 639, Loss: 2.2871631549104485\n",
      "Accuracy 0.14\n",
      "Epoch 640, Loss: 2.2871310887607126\n",
      "Accuracy 0.14\n",
      "Epoch 641, Loss: 2.2870986893943352\n",
      "Accuracy 0.14\n",
      "Epoch 642, Loss: 2.287065949815197\n",
      "Accuracy 0.14\n",
      "Epoch 643, Loss: 2.2870328692174344\n",
      "Accuracy 0.14\n",
      "Epoch 644, Loss: 2.2869994428916236\n",
      "Accuracy 0.14\n",
      "Epoch 645, Loss: 2.28696566672688\n",
      "Accuracy 0.14\n",
      "Epoch 646, Loss: 2.286931535372138\n",
      "Accuracy 0.14\n",
      "Epoch 647, Loss: 2.286897046358087\n",
      "Accuracy 0.14\n",
      "Epoch 648, Loss: 2.286862194585205\n",
      "Accuracy 0.14\n",
      "Epoch 649, Loss: 2.2868269765216938\n",
      "Accuracy 0.14\n",
      "Epoch 650, Loss: 2.2867913797234554\n",
      "Accuracy 0.14\n",
      "Epoch 651, Loss: 2.286755396215988\n",
      "Accuracy 0.14\n",
      "Epoch 652, Loss: 2.2867190229874677\n",
      "Accuracy 0.14\n",
      "Epoch 653, Loss: 2.2866822570608223\n",
      "Accuracy 0.14\n",
      "Epoch 654, Loss: 2.2866450884735485\n",
      "Accuracy 0.14\n",
      "Epoch 655, Loss: 2.286607513420036\n",
      "Accuracy 0.14\n",
      "Epoch 656, Loss: 2.2865695231377967\n",
      "Accuracy 0.14\n",
      "Epoch 657, Loss: 2.2865311118640403\n",
      "Accuracy 0.14\n",
      "Epoch 658, Loss: 2.2864922853481002\n",
      "Accuracy 0.14\n",
      "Epoch 659, Loss: 2.286453030319165\n",
      "Accuracy 0.14\n",
      "Epoch 660, Loss: 2.2864133378212883\n",
      "Accuracy 0.14\n",
      "Epoch 661, Loss: 2.286373205010525\n",
      "Accuracy 0.14\n",
      "Epoch 662, Loss: 2.2863326177554826\n",
      "Accuracy 0.14\n",
      "Epoch 663, Loss: 2.2862915721407644\n",
      "Accuracy 0.14\n",
      "Epoch 664, Loss: 2.2862500639095114\n",
      "Accuracy 0.14\n",
      "Epoch 665, Loss: 2.2862080869244354\n",
      "Accuracy 0.14\n",
      "Epoch 666, Loss: 2.2861656248410527\n",
      "Accuracy 0.14\n",
      "Epoch 667, Loss: 2.2861226731143898\n",
      "Accuracy 0.14\n",
      "Epoch 668, Loss: 2.286079229962652\n",
      "Accuracy 0.14\n",
      "Epoch 669, Loss: 2.2860352830920374\n",
      "Accuracy 0.14\n",
      "Epoch 670, Loss: 2.285990818628468\n",
      "Accuracy 0.14\n",
      "Epoch 671, Loss: 2.2859458316441104\n",
      "Accuracy 0.14\n",
      "Epoch 672, Loss: 2.285900322621743\n",
      "Accuracy 0.14\n",
      "Epoch 673, Loss: 2.2858542836416746\n",
      "Accuracy 0.14\n",
      "Epoch 674, Loss: 2.2858077028830897\n",
      "Accuracy 0.14\n",
      "Epoch 675, Loss: 2.2857605692392364\n",
      "Accuracy 0.14\n",
      "Epoch 676, Loss: 2.2857128796319097\n",
      "Accuracy 0.14\n",
      "Epoch 677, Loss: 2.285664620646768\n",
      "Accuracy 0.14\n",
      "Epoch 678, Loss: 2.2856157825841357\n",
      "Accuracy 0.14\n",
      "Epoch 679, Loss: 2.2855663560759685\n",
      "Accuracy 0.14\n",
      "Epoch 680, Loss: 2.2855163316026137\n",
      "Accuracy 0.14\n",
      "Epoch 681, Loss: 2.2854656952074413\n",
      "Accuracy 0.14\n",
      "Epoch 682, Loss: 2.285414441351721\n",
      "Accuracy 0.14\n",
      "Epoch 683, Loss: 2.285362562365973\n",
      "Accuracy 0.14\n",
      "Epoch 684, Loss: 2.2853100520305056\n",
      "Accuracy 0.14\n",
      "Epoch 685, Loss: 2.285256899585542\n",
      "Accuracy 0.14\n",
      "Epoch 686, Loss: 2.2852030869534734\n",
      "Accuracy 0.14\n",
      "Epoch 687, Loss: 2.2851485982939512\n",
      "Accuracy 0.14\n",
      "Epoch 688, Loss: 2.285093430999281\n",
      "Accuracy 0.14\n",
      "Epoch 689, Loss: 2.285037562075616\n",
      "Accuracy 0.14\n",
      "Epoch 690, Loss: 2.284980986679014\n",
      "Accuracy 0.14\n",
      "Epoch 691, Loss: 2.284923688753982\n",
      "Accuracy 0.14\n",
      "Epoch 692, Loss: 2.2848656592595087\n",
      "Accuracy 0.14\n",
      "Epoch 693, Loss: 2.2848068879805536\n",
      "Accuracy 0.14\n",
      "Epoch 694, Loss: 2.284747358403264\n",
      "Accuracy 0.14\n",
      "Epoch 695, Loss: 2.2846870632290717\n",
      "Accuracy 0.14\n",
      "Epoch 696, Loss: 2.2846259913928937\n",
      "Accuracy 0.14\n",
      "Epoch 697, Loss: 2.2845641296811032\n",
      "Accuracy 0.14\n",
      "Epoch 698, Loss: 2.2845014665035346\n",
      "Accuracy 0.14\n",
      "Epoch 699, Loss: 2.28443797939354\n",
      "Accuracy 0.14\n",
      "Epoch 700, Loss: 2.2843736511948562\n",
      "Accuracy 0.14\n",
      "Epoch 701, Loss: 2.2843084669937967\n",
      "Accuracy 0.14\n",
      "Epoch 702, Loss: 2.284242421448452\n",
      "Accuracy 0.14\n",
      "Epoch 703, Loss: 2.2841754926630453\n",
      "Accuracy 0.14\n",
      "Epoch 704, Loss: 2.2841076631962314\n",
      "Accuracy 0.14\n",
      "Epoch 705, Loss: 2.2840389169205064\n",
      "Accuracy 0.14\n",
      "Epoch 706, Loss: 2.2839692422644022\n",
      "Accuracy 0.14\n",
      "Epoch 707, Loss: 2.283898617260511\n",
      "Accuracy 0.14\n",
      "Epoch 708, Loss: 2.283827025809048\n",
      "Accuracy 0.14\n",
      "Epoch 709, Loss: 2.2837544452978955\n",
      "Accuracy 0.14\n",
      "Epoch 710, Loss: 2.283680858316676\n",
      "Accuracy 0.14\n",
      "Epoch 711, Loss: 2.283606245069832\n",
      "Accuracy 0.14\n",
      "Epoch 712, Loss: 2.283530587599193\n",
      "Accuracy 0.14\n",
      "Epoch 713, Loss: 2.2834538688871833\n",
      "Accuracy 0.14\n",
      "Epoch 714, Loss: 2.283376065100054\n",
      "Accuracy 0.14\n",
      "Epoch 715, Loss: 2.283297154623557\n",
      "Accuracy 0.14\n",
      "Epoch 716, Loss: 2.2832171135647963\n",
      "Accuracy 0.14\n",
      "Epoch 717, Loss: 2.283135927151172\n",
      "Accuracy 0.14\n",
      "Epoch 718, Loss: 2.2830535697925987\n",
      "Accuracy 0.14\n",
      "Epoch 719, Loss: 2.282970022463363\n",
      "Accuracy 0.14\n",
      "Epoch 720, Loss: 2.2828852591549857\n",
      "Accuracy 0.14\n",
      "Epoch 721, Loss: 2.282799254995955\n",
      "Accuracy 0.14\n",
      "Epoch 722, Loss: 2.282711978513964\n",
      "Accuracy 0.14\n",
      "Epoch 723, Loss: 2.282623411491564\n",
      "Accuracy 0.14\n",
      "Epoch 724, Loss: 2.2825335264962967\n",
      "Accuracy 0.14\n",
      "Epoch 725, Loss: 2.282442291660164\n",
      "Accuracy 0.14\n",
      "Epoch 726, Loss: 2.2823496956891316\n",
      "Accuracy 0.14\n",
      "Epoch 727, Loss: 2.2822557005269517\n",
      "Accuracy 0.14\n",
      "Epoch 728, Loss: 2.2821602814364814\n",
      "Accuracy 0.14\n",
      "Epoch 729, Loss: 2.2820634092575016\n",
      "Accuracy 0.14\n",
      "Epoch 730, Loss: 2.2819650461831125\n",
      "Accuracy 0.14\n",
      "Epoch 731, Loss: 2.281865168484676\n",
      "Accuracy 0.14\n",
      "Epoch 732, Loss: 2.2817637346124746\n",
      "Accuracy 0.14\n",
      "Epoch 733, Loss: 2.2816607266175826\n",
      "Accuracy 0.14\n",
      "Epoch 734, Loss: 2.2815561039295873\n",
      "Accuracy 0.14\n",
      "Epoch 735, Loss: 2.2814498342877916\n",
      "Accuracy 0.14\n",
      "Epoch 736, Loss: 2.281341878835129\n",
      "Accuracy 0.14\n",
      "Epoch 737, Loss: 2.2812322006855092\n",
      "Accuracy 0.14\n",
      "Epoch 738, Loss: 2.281120755516161\n",
      "Accuracy 0.14\n",
      "Epoch 739, Loss: 2.2810075118039546\n",
      "Accuracy 0.14\n",
      "Epoch 740, Loss: 2.2808924327149205\n",
      "Accuracy 0.14\n",
      "Epoch 741, Loss: 2.2807754769802724\n",
      "Accuracy 0.14\n",
      "Epoch 742, Loss: 2.280656601048135\n",
      "Accuracy 0.14\n",
      "Epoch 743, Loss: 2.2805357621005844\n",
      "Accuracy 0.14\n",
      "Epoch 744, Loss: 2.2804129076461006\n",
      "Accuracy 0.14\n",
      "Epoch 745, Loss: 2.2802880074281884\n",
      "Accuracy 0.14\n",
      "Epoch 746, Loss: 2.2801610151502363\n",
      "Accuracy 0.14\n",
      "Epoch 747, Loss: 2.2800318837166413\n",
      "Accuracy 0.14\n",
      "Epoch 748, Loss: 2.2799005512395696\n",
      "Accuracy 0.14\n",
      "Epoch 749, Loss: 2.279766963419268\n",
      "Accuracy 0.14\n",
      "Epoch 750, Loss: 2.279631065556456\n",
      "Accuracy 0.14\n",
      "Epoch 751, Loss: 2.2794928035981683\n",
      "Accuracy 0.14\n",
      "Epoch 752, Loss: 2.2793521164400663\n",
      "Accuracy 0.14\n",
      "Epoch 753, Loss: 2.2792089523307646\n",
      "Accuracy 0.14\n",
      "Epoch 754, Loss: 2.279063243336254\n",
      "Accuracy 0.14\n",
      "Epoch 755, Loss: 2.2789149465541088\n",
      "Accuracy 0.14\n",
      "Epoch 756, Loss: 2.27876400128385\n",
      "Accuracy 0.14\n",
      "Epoch 757, Loss: 2.278610318656115\n",
      "Accuracy 0.14\n",
      "Epoch 758, Loss: 2.278453851349577\n",
      "Accuracy 0.14\n",
      "Epoch 759, Loss: 2.278294533221882\n",
      "Accuracy 0.14\n",
      "Epoch 760, Loss: 2.2781322733360656\n",
      "Accuracy 0.14\n",
      "Epoch 761, Loss: 2.277966990750682\n",
      "Accuracy 0.14\n",
      "Epoch 762, Loss: 2.2777986147179354\n",
      "Accuracy 0.14\n",
      "Epoch 763, Loss: 2.277627080882001\n",
      "Accuracy 0.14\n",
      "Epoch 764, Loss: 2.277452301125621\n",
      "Accuracy 0.14\n",
      "Epoch 765, Loss: 2.277274194895821\n",
      "Accuracy 0.14\n",
      "Epoch 766, Loss: 2.27709267924497\n",
      "Accuracy 0.14\n",
      "Epoch 767, Loss: 2.2769076609118413\n",
      "Accuracy 0.14\n",
      "Epoch 768, Loss: 2.276719055575394\n",
      "Accuracy 0.14\n",
      "Epoch 769, Loss: 2.2765267605968713\n",
      "Accuracy 0.14\n",
      "Epoch 770, Loss: 2.276330677553043\n",
      "Accuracy 0.14\n",
      "Epoch 771, Loss: 2.276130690503956\n",
      "Accuracy 0.14\n",
      "Epoch 772, Loss: 2.2759266796295288\n",
      "Accuracy 0.14\n",
      "Epoch 773, Loss: 2.2757185461745766\n",
      "Accuracy 0.14\n",
      "Epoch 774, Loss: 2.2755061781679533\n",
      "Accuracy 0.14\n",
      "Epoch 775, Loss: 2.2752894407060484\n",
      "Accuracy 0.14\n",
      "Epoch 776, Loss: 2.2750682132927875\n",
      "Accuracy 0.14\n",
      "Epoch 777, Loss: 2.2748423863404907\n",
      "Accuracy 0.14\n",
      "Epoch 778, Loss: 2.2746118382122833\n",
      "Accuracy 0.14\n",
      "Epoch 779, Loss: 2.274376421806529\n",
      "Accuracy 0.14\n",
      "Epoch 780, Loss: 2.274135978740981\n",
      "Accuracy 0.14\n",
      "Epoch 781, Loss: 2.273890373896692\n",
      "Accuracy 0.14\n",
      "Epoch 782, Loss: 2.273639431816894\n",
      "Accuracy 0.14\n",
      "Epoch 783, Loss: 2.273383008858693\n",
      "Accuracy 0.14\n",
      "Epoch 784, Loss: 2.2731209479531187\n",
      "Accuracy 0.14\n",
      "Epoch 785, Loss: 2.272853066080525\n",
      "Accuracy 0.14\n",
      "Epoch 786, Loss: 2.2725791942643134\n",
      "Accuracy 0.15\n",
      "Epoch 787, Loss: 2.272299134001305\n",
      "Accuracy 0.15\n",
      "Epoch 788, Loss: 2.272012694220911\n",
      "Accuracy 0.15\n",
      "Epoch 789, Loss: 2.271719684095942\n",
      "Accuracy 0.15\n",
      "Epoch 790, Loss: 2.2714198574045996\n",
      "Accuracy 0.15\n",
      "Epoch 791, Loss: 2.2711130142226974\n",
      "Accuracy 0.15\n",
      "Epoch 792, Loss: 2.2707989202396193\n",
      "Accuracy 0.15\n",
      "Epoch 793, Loss: 2.27047735728931\n",
      "Accuracy 0.15\n",
      "Epoch 794, Loss: 2.2701480850296614\n",
      "Accuracy 0.15\n",
      "Epoch 795, Loss: 2.269810851468885\n",
      "Accuracy 0.16\n",
      "Epoch 796, Loss: 2.26946540780957\n",
      "Accuracy 0.16\n",
      "Epoch 797, Loss: 2.2691114663995653\n",
      "Accuracy 0.16\n",
      "Epoch 798, Loss: 2.2687487238969912\n",
      "Accuracy 0.16\n",
      "Epoch 799, Loss: 2.268376864954842\n",
      "Accuracy 0.16\n",
      "Epoch 800, Loss: 2.267995517912322\n",
      "Accuracy 0.17\n",
      "Epoch 801, Loss: 2.2676044331488403\n",
      "Accuracy 0.17\n",
      "Epoch 802, Loss: 2.2672033013160906\n",
      "Accuracy 0.17\n",
      "Epoch 803, Loss: 2.266791716946268\n",
      "Accuracy 0.17\n",
      "Epoch 804, Loss: 2.2663692910391475\n",
      "Accuracy 0.17\n",
      "Epoch 805, Loss: 2.2659356462019433\n",
      "Accuracy 0.17\n",
      "Epoch 806, Loss: 2.265490385159526\n",
      "Accuracy 0.17\n",
      "Epoch 807, Loss: 2.2650331076334083\n",
      "Accuracy 0.18\n",
      "Epoch 808, Loss: 2.264563356251447\n",
      "Accuracy 0.18\n",
      "Epoch 809, Loss: 2.2640806525352954\n",
      "Accuracy 0.18\n",
      "Epoch 810, Loss: 2.263584522965062\n",
      "Accuracy 0.18\n",
      "Epoch 811, Loss: 2.2630744372530343\n",
      "Accuracy 0.18\n",
      "Epoch 812, Loss: 2.2625498837483993\n",
      "Accuracy 0.18\n",
      "Epoch 813, Loss: 2.2620103160515423\n",
      "Accuracy 0.2\n",
      "Epoch 814, Loss: 2.2614551434614527\n",
      "Accuracy 0.2\n",
      "Epoch 815, Loss: 2.260883770803161\n",
      "Accuracy 0.2\n",
      "Epoch 816, Loss: 2.2602955455396603\n",
      "Accuracy 0.2\n",
      "Epoch 817, Loss: 2.259689844483146\n",
      "Accuracy 0.2\n",
      "Epoch 818, Loss: 2.2590659433992086\n",
      "Accuracy 0.2\n",
      "Epoch 819, Loss: 2.2584231124622285\n",
      "Accuracy 0.2\n",
      "Epoch 820, Loss: 2.25776055970984\n",
      "Accuracy 0.21\n",
      "Epoch 821, Loss: 2.257077534608718\n",
      "Accuracy 0.21\n",
      "Epoch 822, Loss: 2.256373209717569\n",
      "Accuracy 0.21\n",
      "Epoch 823, Loss: 2.2556466685084344\n",
      "Accuracy 0.22\n",
      "Epoch 824, Loss: 2.254896978360966\n",
      "Accuracy 0.22\n",
      "Epoch 825, Loss: 2.254123210362226\n",
      "Accuracy 0.22\n",
      "Epoch 826, Loss: 2.2533243139340695\n",
      "Accuracy 0.22\n",
      "Epoch 827, Loss: 2.252499337875479\n",
      "Accuracy 0.22\n",
      "Epoch 828, Loss: 2.2516471892636396\n",
      "Accuracy 0.22\n",
      "Epoch 829, Loss: 2.2507667351664593\n",
      "Accuracy 0.22\n",
      "Epoch 830, Loss: 2.249856837052932\n",
      "Accuracy 0.22\n",
      "Epoch 831, Loss: 2.248916217119979\n",
      "Accuracy 0.22\n",
      "Epoch 832, Loss: 2.247943608396388\n",
      "Accuracy 0.22\n",
      "Epoch 833, Loss: 2.246937693215495\n",
      "Accuracy 0.22\n",
      "Epoch 834, Loss: 2.2458971781116874\n",
      "Accuracy 0.22\n",
      "Epoch 835, Loss: 2.24482058841836\n",
      "Accuracy 0.22\n",
      "Epoch 836, Loss: 2.243706466053498\n",
      "Accuracy 0.22\n",
      "Epoch 837, Loss: 2.2425533030278912\n",
      "Accuracy 0.22\n",
      "Epoch 838, Loss: 2.241359599907109\n",
      "Accuracy 0.22\n",
      "Epoch 839, Loss: 2.2401237119884465\n",
      "Accuracy 0.22\n",
      "Epoch 840, Loss: 2.238844046909934\n",
      "Accuracy 0.22\n",
      "Epoch 841, Loss: 2.2375188846922867\n",
      "Accuracy 0.22\n",
      "Epoch 842, Loss: 2.2361464088413494\n",
      "Accuracy 0.22\n",
      "Epoch 843, Loss: 2.2347251481112744\n",
      "Accuracy 0.22\n",
      "Epoch 844, Loss: 2.23325335651375\n",
      "Accuracy 0.22\n",
      "Epoch 845, Loss: 2.2317293119247945\n",
      "Accuracy 0.22\n",
      "Epoch 846, Loss: 2.230151376195593\n",
      "Accuracy 0.22\n",
      "Epoch 847, Loss: 2.228517922658339\n",
      "Accuracy 0.22\n",
      "Epoch 848, Loss: 2.2268272390242463\n",
      "Accuracy 0.22\n",
      "Epoch 849, Loss: 2.2250777507202346\n",
      "Accuracy 0.22\n",
      "Epoch 850, Loss: 2.2232680230359327\n",
      "Accuracy 0.22\n",
      "Epoch 851, Loss: 2.221396834960483\n",
      "Accuracy 0.22\n",
      "Epoch 852, Loss: 2.2194628299401917\n",
      "Accuracy 0.22\n",
      "Epoch 853, Loss: 2.2174649659469563\n",
      "Accuracy 0.22\n",
      "Epoch 854, Loss: 2.215402281865472\n",
      "Accuracy 0.22\n",
      "Epoch 855, Loss: 2.2132740182936104\n",
      "Accuracy 0.22\n",
      "Epoch 856, Loss: 2.211079790500706\n",
      "Accuracy 0.22\n",
      "Epoch 857, Loss: 2.208819335374355\n",
      "Accuracy 0.22\n",
      "Epoch 858, Loss: 2.2064927049764997\n",
      "Accuracy 0.22\n",
      "Epoch 859, Loss: 2.2041003087506588\n",
      "Accuracy 0.22\n",
      "Epoch 860, Loss: 2.201642844859237\n",
      "Accuracy 0.22\n",
      "Epoch 861, Loss: 2.1991213628196\n",
      "Accuracy 0.22\n",
      "Epoch 862, Loss: 2.196537326682372\n",
      "Accuracy 0.22\n",
      "Epoch 863, Loss: 2.1938926447831726\n",
      "Accuracy 0.22\n",
      "Epoch 864, Loss: 2.1911892630207523\n",
      "Accuracy 0.22\n",
      "Epoch 865, Loss: 2.1884297819367444\n",
      "Accuracy 0.22\n",
      "Epoch 866, Loss: 2.185617051484756\n",
      "Accuracy 0.22\n",
      "Epoch 867, Loss: 2.182754219701096\n",
      "Accuracy 0.22\n",
      "Epoch 868, Loss: 2.179845568681096\n",
      "Accuracy 0.22\n",
      "Epoch 869, Loss: 2.1768941760489735\n",
      "Accuracy 0.22\n",
      "Epoch 870, Loss: 2.17390440865822\n",
      "Accuracy 0.22\n",
      "Epoch 871, Loss: 2.1708807501326355\n",
      "Accuracy 0.22\n",
      "Epoch 872, Loss: 2.16782684246821\n",
      "Accuracy 0.22\n",
      "Epoch 873, Loss: 2.164746775960299\n",
      "Accuracy 0.22\n",
      "Epoch 874, Loss: 2.161645124843876\n",
      "Accuracy 0.22\n",
      "Epoch 875, Loss: 2.158526214638038\n",
      "Accuracy 0.22\n",
      "Epoch 876, Loss: 2.1553934662319616\n",
      "Accuracy 0.22\n",
      "Epoch 877, Loss: 2.1522504741183495\n",
      "Accuracy 0.22\n",
      "Epoch 878, Loss: 2.149100480252131\n",
      "Accuracy 0.22\n",
      "Epoch 879, Loss: 2.145945136301308\n",
      "Accuracy 0.22\n",
      "Epoch 880, Loss: 2.142786882784881\n",
      "Accuracy 0.22\n",
      "Epoch 881, Loss: 2.1396279512075753\n",
      "Accuracy 0.22\n",
      "Epoch 882, Loss: 2.136469478046502\n",
      "Accuracy 0.22\n",
      "Epoch 883, Loss: 2.1333122067969543\n",
      "Accuracy 0.22\n",
      "Epoch 884, Loss: 2.130156356746804\n",
      "Accuracy 0.22\n",
      "Epoch 885, Loss: 2.127003246132775\n",
      "Accuracy 0.22\n",
      "Epoch 886, Loss: 2.123853891565818\n",
      "Accuracy 0.22\n",
      "Epoch 887, Loss: 2.1207058240320014\n",
      "Accuracy 0.22\n",
      "Epoch 888, Loss: 2.1175645345756657\n",
      "Accuracy 0.22\n",
      "Epoch 889, Loss: 2.1144301362589233\n",
      "Accuracy 0.22\n",
      "Epoch 890, Loss: 2.111302280151126\n",
      "Accuracy 0.22\n",
      "Epoch 891, Loss: 2.108180006068105\n",
      "Accuracy 0.22\n",
      "Epoch 892, Loss: 2.105061529049427\n",
      "Accuracy 0.22\n",
      "Epoch 893, Loss: 2.1019474196595813\n",
      "Accuracy 0.22\n",
      "Epoch 894, Loss: 2.0988367809746222\n",
      "Accuracy 0.22\n",
      "Epoch 895, Loss: 2.0957330026892405\n",
      "Accuracy 0.22\n",
      "Epoch 896, Loss: 2.0926348683379348\n",
      "Accuracy 0.22\n",
      "Epoch 897, Loss: 2.0895418654176634\n",
      "Accuracy 0.22\n",
      "Epoch 898, Loss: 2.086451747862479\n",
      "Accuracy 0.22\n",
      "Epoch 899, Loss: 2.083364165945605\n",
      "Accuracy 0.22\n",
      "Epoch 900, Loss: 2.0802782631767474\n",
      "Accuracy 0.22\n",
      "Epoch 901, Loss: 2.0771939122241485\n",
      "Accuracy 0.22\n",
      "Epoch 902, Loss: 2.074112294900892\n",
      "Accuracy 0.22\n",
      "Epoch 903, Loss: 2.071036408414766\n",
      "Accuracy 0.22\n",
      "Epoch 904, Loss: 2.0679631641000293\n",
      "Accuracy 0.22\n",
      "Epoch 905, Loss: 2.0648928171210255\n",
      "Accuracy 0.22\n",
      "Epoch 906, Loss: 2.061825734948619\n",
      "Accuracy 0.22\n",
      "Epoch 907, Loss: 2.0587599616045376\n",
      "Accuracy 0.22\n",
      "Epoch 908, Loss: 2.05569566602085\n",
      "Accuracy 0.22\n",
      "Epoch 909, Loss: 2.0526332298616836\n",
      "Accuracy 0.22\n",
      "Epoch 910, Loss: 2.0495727791262435\n",
      "Accuracy 0.22\n",
      "Epoch 911, Loss: 2.046515911145225\n",
      "Accuracy 0.22\n",
      "Epoch 912, Loss: 2.0434618964773588\n",
      "Accuracy 0.22\n",
      "Epoch 913, Loss: 2.0404104387310738\n",
      "Accuracy 0.22\n",
      "Epoch 914, Loss: 2.037361495952\n",
      "Accuracy 0.22\n",
      "Epoch 915, Loss: 2.0343132898379155\n",
      "Accuracy 0.22\n",
      "Epoch 916, Loss: 2.0312654685487166\n",
      "Accuracy 0.22\n",
      "Epoch 917, Loss: 2.028217162508161\n",
      "Accuracy 0.22\n",
      "Epoch 918, Loss: 2.0251693201567127\n",
      "Accuracy 0.22\n",
      "Epoch 919, Loss: 2.0221220435289884\n",
      "Accuracy 0.22\n",
      "Epoch 920, Loss: 2.0190729366061158\n",
      "Accuracy 0.22\n",
      "Epoch 921, Loss: 2.016022174921388\n",
      "Accuracy 0.22\n",
      "Epoch 922, Loss: 2.012969270545873\n",
      "Accuracy 0.22\n",
      "Epoch 923, Loss: 2.0099138594908883\n",
      "Accuracy 0.22\n",
      "Epoch 924, Loss: 2.006855300011447\n",
      "Accuracy 0.22\n",
      "Epoch 925, Loss: 2.003792598009912\n",
      "Accuracy 0.22\n",
      "Epoch 926, Loss: 2.0007263791020553\n",
      "Accuracy 0.22\n",
      "Epoch 927, Loss: 1.9976545054924053\n",
      "Accuracy 0.22\n",
      "Epoch 928, Loss: 1.9945766393419626\n",
      "Accuracy 0.22\n",
      "Epoch 929, Loss: 1.9914924189887997\n",
      "Accuracy 0.22\n",
      "Epoch 930, Loss: 1.9884008968780065\n",
      "Accuracy 0.22\n",
      "Epoch 931, Loss: 1.9853016077165844\n",
      "Accuracy 0.22\n",
      "Epoch 932, Loss: 1.9821932100965947\n",
      "Accuracy 0.22\n",
      "Epoch 933, Loss: 1.9790750670317434\n",
      "Accuracy 0.22\n",
      "Epoch 934, Loss: 1.9759459955978083\n",
      "Accuracy 0.22\n",
      "Epoch 935, Loss: 1.9728054245058864\n",
      "Accuracy 0.22\n",
      "Epoch 936, Loss: 1.9696536628911858\n",
      "Accuracy 0.22\n",
      "Epoch 937, Loss: 1.9664882963196093\n",
      "Accuracy 0.22\n",
      "Epoch 938, Loss: 1.9633080286787605\n",
      "Accuracy 0.22\n",
      "Epoch 939, Loss: 1.960112023602094\n",
      "Accuracy 0.22\n",
      "Epoch 940, Loss: 1.9568990877651318\n",
      "Accuracy 0.22\n",
      "Epoch 941, Loss: 1.9536685596035532\n",
      "Accuracy 0.22\n",
      "Epoch 942, Loss: 1.9504191603729286\n",
      "Accuracy 0.22\n",
      "Epoch 943, Loss: 1.947149173332353\n",
      "Accuracy 0.22\n",
      "Epoch 944, Loss: 1.9438578899504517\n",
      "Accuracy 0.22\n",
      "Epoch 945, Loss: 1.940543808033769\n",
      "Accuracy 0.22\n",
      "Epoch 946, Loss: 1.9372061330675385\n",
      "Accuracy 0.22\n",
      "Epoch 947, Loss: 1.93384335658598\n",
      "Accuracy 0.22\n",
      "Epoch 948, Loss: 1.9304545241652364\n",
      "Accuracy 0.22\n",
      "Epoch 949, Loss: 1.9270387011411667\n",
      "Accuracy 0.23\n",
      "Epoch 950, Loss: 1.9235948990072265\n",
      "Accuracy 0.23\n",
      "Epoch 951, Loss: 1.9201203819124912\n",
      "Accuracy 0.23\n",
      "Epoch 952, Loss: 1.9166137347126833\n",
      "Accuracy 0.23\n",
      "Epoch 953, Loss: 1.9130745109923089\n",
      "Accuracy 0.25\n",
      "Epoch 954, Loss: 1.909500190982809\n",
      "Accuracy 0.25\n",
      "Epoch 955, Loss: 1.9058906214283402\n",
      "Accuracy 0.25\n",
      "Epoch 956, Loss: 1.9022451304486947\n",
      "Accuracy 0.25\n",
      "Epoch 957, Loss: 1.8985619628188801\n",
      "Accuracy 0.25\n",
      "Epoch 958, Loss: 1.8948393655269702\n",
      "Accuracy 0.25\n",
      "Epoch 959, Loss: 1.8910749382624599\n",
      "Accuracy 0.25\n",
      "Epoch 960, Loss: 1.8872674860260563\n",
      "Accuracy 0.25\n",
      "Epoch 961, Loss: 1.8834163941712807\n",
      "Accuracy 0.26\n",
      "Epoch 962, Loss: 1.8795198518357292\n",
      "Accuracy 0.27\n",
      "Epoch 963, Loss: 1.8755779738318652\n",
      "Accuracy 0.27\n",
      "Epoch 964, Loss: 1.8715896889938712\n",
      "Accuracy 0.27\n",
      "Epoch 965, Loss: 1.8675519294875067\n",
      "Accuracy 0.27\n",
      "Epoch 966, Loss: 1.86346367819886\n",
      "Accuracy 0.28\n",
      "Epoch 967, Loss: 1.8593263434094154\n",
      "Accuracy 0.28\n",
      "Epoch 968, Loss: 1.8551370752597276\n",
      "Accuracy 0.28\n",
      "Epoch 969, Loss: 1.850894425309195\n",
      "Accuracy 0.28\n",
      "Epoch 970, Loss: 1.8465987650391822\n",
      "Accuracy 0.28\n",
      "Epoch 971, Loss: 1.8422510515848216\n",
      "Accuracy 0.28\n",
      "Epoch 972, Loss: 1.8378492714847223\n",
      "Accuracy 0.28\n",
      "Epoch 973, Loss: 1.8333926171638686\n",
      "Accuracy 0.28\n",
      "Epoch 974, Loss: 1.8288820441377178\n",
      "Accuracy 0.28\n",
      "Epoch 975, Loss: 1.8243177791512717\n",
      "Accuracy 0.29\n",
      "Epoch 976, Loss: 1.8196999464961774\n",
      "Accuracy 0.29\n",
      "Epoch 977, Loss: 1.8150297675563671\n",
      "Accuracy 0.29\n",
      "Epoch 978, Loss: 1.8103075922995044\n",
      "Accuracy 0.29\n",
      "Epoch 979, Loss: 1.805533031892055\n",
      "Accuracy 0.28\n",
      "Epoch 980, Loss: 1.800707577134952\n",
      "Accuracy 0.28\n",
      "Epoch 981, Loss: 1.795831464117448\n",
      "Accuracy 0.29\n",
      "Epoch 982, Loss: 1.790905831227396\n",
      "Accuracy 0.3\n",
      "Epoch 983, Loss: 1.7859332217492299\n",
      "Accuracy 0.3\n",
      "Epoch 984, Loss: 1.7809139291736964\n",
      "Accuracy 0.3\n",
      "Epoch 985, Loss: 1.7758493788892082\n",
      "Accuracy 0.3\n",
      "Epoch 986, Loss: 1.7707416863438015\n",
      "Accuracy 0.3\n",
      "Epoch 987, Loss: 1.7655922295116844\n",
      "Accuracy 0.3\n",
      "Epoch 988, Loss: 1.7604005264980596\n",
      "Accuracy 0.3\n",
      "Epoch 989, Loss: 1.7551684387948923\n",
      "Accuracy 0.31\n",
      "Epoch 990, Loss: 1.749899336234214\n",
      "Accuracy 0.31\n",
      "Epoch 991, Loss: 1.7445956446917872\n",
      "Accuracy 0.31\n",
      "Epoch 992, Loss: 1.7392569550685935\n",
      "Accuracy 0.31\n",
      "Epoch 993, Loss: 1.7338879859830754\n",
      "Accuracy 0.31\n",
      "Epoch 994, Loss: 1.7284848891618663\n",
      "Accuracy 0.31\n",
      "Epoch 995, Loss: 1.7230477505315895\n",
      "Accuracy 0.31\n",
      "Epoch 996, Loss: 1.7175790862334324\n",
      "Accuracy 0.31\n",
      "Epoch 997, Loss: 1.7120791393339085\n",
      "Accuracy 0.31\n",
      "Epoch 998, Loss: 1.706546007475172\n",
      "Accuracy 0.31\n",
      "Epoch 999, Loss: 1.700981184592944\n",
      "Accuracy 0.32\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9170e6ad532b055c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
